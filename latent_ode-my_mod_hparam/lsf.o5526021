Lmod has detected the following error: The following module(s) are unknown:
"cuda/10.0.13" "pytorch/1.4.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/10.0.13" "pytorch/1.4.0"



Couldn't import umap
Sampling dataset of 300000 training examples

Trainingdataset:
Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

Using Evaluationdataset:
Dataset Crops
    Number of datapoints: 1000
    Root Location: data/Crops
    Reduce: average

  0%|          | 0/30 [00:00<?, ?trial/s, best loss=?]                                                      runs/expID9141057_TRAINode_ns:300000_ba:500_ode-units:500_gru-uts:50_lats:35_rec-lay:4_solver:dopri5_seed:6003_optim:adamax
  0%|          | 0/30 [00:00<?, ?trial/s, best loss=?]job exception: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 7.93 GiB total capacity; 7.29 GiB already allocated; 2.56 MiB free; 7.40 GiB reserved in total by PyTorch)

  0%|          | 0/30 [00:05<?, ?trial/s, best loss=?]

-----------------------------------------------------------------------------------------------------------------
TRIAL PROTOCOL:
-----------------------------------------------------------------------------------------------------------------
-----------------------------------------------------------------------------------------------------------------
Traceback (most recent call last):
  File "run_models.py", line 178, in <module>
    max_evals=30)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/hyperopt/fmin.py", line 482, in fmin
    show_progressbar=show_progressbar,
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/hyperopt/base.py", line 686, in fmin
    show_progressbar=show_progressbar,
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/hyperopt/fmin.py", line 509, in fmin
    rval.exhaust()
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/hyperopt/fmin.py", line 330, in exhaust
    self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/hyperopt/fmin.py", line 286, in run
    self.serial_evaluate()
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/hyperopt/fmin.py", line 165, in serial_evaluate
    result = self.domain.evaluate(spec, ctrl)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/hyperopt/base.py", line 894, in evaluate
    rval = self.fn(pyll_rval)
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/training.py", line 151, in construct_and_train_model
    device
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/training.py", line 229, in train_it
    train_res = model.compute_all_losses(batch_dict, n_traj_samples = 3, kl_coef = kl_coef)
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/base_models.py", line 132, in compute_all_losses
    mode = batch_dict["mode"])
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/ode_rnn.py", line 73, in get_reconstruction
    data_and_mask, truth_time_steps, run_backwards = False)
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/encoder_decoder.py", line 288, in run_odernn
    ode_sol = self.z0_diffeq_solver(prev_y, time_points)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/diffeq_solver.py", line 41, in forward
    rtol=self.odeint_rtol, atol=self.odeint_atol, method = self.ode_method)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/torchdiffeq/_impl/odeint.py", line 76, in odeint
    solution = solver.integrate(t)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/torchdiffeq/_impl/solvers.py", line 31, in integrate
    y = self.advance(t[i])
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/torchdiffeq/_impl/dopri5.py", line 90, in advance
    self.rk_state = self._adaptive_dopri5_step(self.rk_state)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/torchdiffeq/_impl/dopri5.py", line 103, in _adaptive_dopri5_step
    y1, f1, y1_error, k = _runge_kutta_step(self.func, y0, f0, t0, dt, tableau=_DORMAND_PRINCE_SHAMPINE_TABLEAU)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/torchdiffeq/_impl/rk_common.py", line 52, in _runge_kutta_step
    tuple(k_.append(f_) for k_, f_ in zip(k, func(ti, yi)))
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/torchdiffeq/_impl/misc.py", line 187, in <lambda>
    func = lambda t, y: tuple(-f_ for f_ in _base_reverse_func(-t, y))
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/torchdiffeq/_impl/misc.py", line 179, in <lambda>
    func = lambda t, y: (_base_nontuple_func_(t, y[0]),)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/ode_func.py", line 36, in forward
    grad = self.get_ode_gradient_nn(t_local, y)
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/ode_func.py", line 42, in get_ode_gradient_nn
    return self.gradient_net(y)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/torch/nn/modules/activation.py", line 295, in forward
    return torch.tanh(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 7.93 GiB total capacity; 7.29 GiB already allocated; 2.56 MiB free; 7.40 GiB reserved in total by PyTorch)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "run_models.py", line 185, in <module>
    hyperopt_summary(trials)
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/utils.py", line 776, in hyperopt_summary
    best_param
UnboundLocalError: local variable 'best_param' referenced before assignment
