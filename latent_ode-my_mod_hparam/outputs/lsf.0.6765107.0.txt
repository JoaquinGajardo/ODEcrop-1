Lmod has detected the following error: The following module(s) are unknown:
"pytorch/1.4.0" "cuda/10.0.13"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "pytorch/1.4.0" "cuda/10.0.13"



Couldn't import umap
I'm counting gpu's:  1
Means I will train  1  models, with different random seeds
My Devices:  ['cuda:0']
Sampling dataset of 11000000 training examples
  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]                                                     Testing hyperparameters:
  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]                                                     ExperimentID
  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]                                                     [9777000]
  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]                                                     /cluster/scratch/metzgern/ODEcrop/Swisscrop
  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]                                                     dataroot: /cluster/scratch/metzgern/ODEcrop/Swisscrop
  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]                                                     Warning, the specified stacking order is not the same length as the number of stacked layers, taking stack-order as reference.
  0%|          | 0/1 [00:06<?, ?trial/s, best loss=?]                                                     Stack-order: 
  0%|          | 0/1 [00:06<?, ?trial/s, best loss=?]                                                     ['ode_rnn', 'ode_rnn', 'gru']
  0%|          | 0/1 [00:06<?, ?trial/s, best loss=?]                                                     Stacking argument: 
  0%|          | 0/1 [00:06<?, ?trial/s, best loss=?]                                                     1
  0%|          | 0/1 [00:06<?, ?trial/s, best loss=?]2020-06-30 17:47:41.469731: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/extras/CUPTI/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-06-30 17:47:41.472857: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/extras/CUPTI/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-06-30 17:47:41.472894: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
                                                     runs/expID9777000_TRAINode_ns:11000000_ba:400_ode-units:255_gru-uts:100_lats:50_rec-lay:2_solver:euler_seed:6001_optim:adamax_stackin:1['ode_rnn', 'ode_rnn', 'gru']_ODEws_RNNws_BN_rs
  0%|          | 0/1 [00:09<?, ?trial/s, best loss=?]run_models.py --niters 1 -n 11000000 -validn 500000 --val_freq 200 --lrdecay 0.99999 --dataset swisscrop --swissdatatype 2_toplabels -b 400 --ode-rnn --rnn-cell star --stack-order ode_rnn ode_rnn gru -ODEws=True -RNNws=True -RN=True --random-seed 6001 --num-search 1 --lr 0.00762 -g 100 -l 50 -u 255 --rec-layers 2 -v 2 --topper=True -BN=True --step 2 --trunc 9

  0%|                                                                                                                                 | 0/25389 [00:00<?, ?it/s]
job exception: size mismatch, m1: [400 x 102], m2: [100 x 100] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:290

  0%|          | 0/1 [00:11<?, ?trial/s, best loss=?]
ODE-RNN  True
Classic-RNN:  False
Stacked layers:  1
Stacked layers:  ['ode_rnn', 'ode_rnn', 'gru']
ODE-type:  linear
RNN-cell:  star
Weight-sharing ODE:  True
Weight-sharing RNN:  True
Using BN:  True
defaut adapted LR's!!
Used Optimizer: adamax
Used Ode-Solver euler

---------------------------------------------------------------------------------------------------------------------------------------------
TRIAL PROTOCOL:
---------------------------------------------------------------------------------------------------------------------------------------------
---------------------------------------------------------------------------------------------------------------------------------------------
Traceback (most recent call last):
  File "run_models.py", line 263, in <module>
    max_evals=args.num_search)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/hyperopt/fmin.py", line 482, in fmin
    show_progressbar=show_progressbar,
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/hyperopt/base.py", line 686, in fmin
    show_progressbar=show_progressbar,
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/hyperopt/fmin.py", line 509, in fmin
    rval.exhaust()
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/hyperopt/fmin.py", line 330, in exhaust
    self.run(self.max_evals - n_done, block_until_done=self.asynchronous)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/hyperopt/fmin.py", line 286, in run
    self.serial_evaluate()
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/hyperopt/fmin.py", line 165, in serial_evaluate
    result = self.domain.evaluate(spec, ctrl)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/hyperopt/base.py", line 894, in evaluate
    rval = self.fn(pyll_rval)
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/training.py", line 179, in construct_and_train_model
    [Devices[0]]
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/training.py", line 322, in train_it
    train_res[i] = Model[i].compute_all_losses(batch_dict[i], n_traj_samples = 3, kl_coef = kl_coef)
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/base_models.py", line 133, in compute_all_losses
    mode = batch_dict["mode"], save_latents=save_latents)
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/ode_rnn.py", line 348, in get_reconstruction
    input_sequence, truth_time_steps, run_backwards = False, save_latents=save_latents)
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/encoder_decoder.py", line 327, in run_odernn
    yi_ode, prev_std = self.RNN_update(yi_ode, prev_std, xi)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/RNNcells.py", line 94, in forward
    gate_x_K = self.x_K(x) 			# return size torch.Size([1, batch_size, latent_dim])
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 87, in forward
    return F.linear(input, self.weight, self.bias)
  File "/cluster/home/metzgern/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 1372, in linear
    output = input.matmul(weight.t())
RuntimeError: size mismatch, m1: [400 x 102], m2: [100 x 100] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:290

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "run_models.py", line 314, in <module>
    hyperopt_summary(trials)
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/utils.py", line 882, in hyperopt_summary
    np.sqrt(best_var)*100,
UnboundLocalError: local variable 'best_var' referenced before assignment
