Lmod has detected the following error: The following module(s) are unknown:
"pytorch/1.4.0" "cuda/10.0.13"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "pytorch/1.4.0" "cuda/10.0.13"



Couldn't import umap
I'm counting gpu's:  1
Means I will train  1  models, with different random seeds
My Devices:  ['cuda:0']
Sampling dataset of 300000 training examples
  0%|          | 0/15 [00:00<?, ?trial/s, best loss=?]                                                      Testing hyperparameters:
  0%|          | 0/15 [00:00<?, ?trial/s, best loss=?]                                                      lr : 0.0030351383205042787
  0%|          | 0/15 [00:00<?, ?trial/s, best loss=?]                                                      Trainingdataset:
  0%|          | 0/15 [00:06<?, ?trial/s, best loss=?]                                                      Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

  0%|          | 0/15 [00:06<?, ?trial/s, best loss=?]                                                      Using Evaluationdataset:
  0%|          | 0/15 [00:06<?, ?trial/s, best loss=?]                                                      Dataset Crops
    Number of datapoints: 55740
    Root Location: data/Crops
    Reduce: average

  0%|          | 0/15 [00:06<?, ?trial/s, best loss=?]                                                      Warning, the specified stacking order is not the same length as the number of stacked layers, taking stack-order as reference.
  0%|          | 0/15 [00:06<?, ?trial/s, best loss=?]2020-05-04 04:35:35.001434: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/extras/CUPTI/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-05-04 04:35:35.001874: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/extras/CUPTI/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-05-04 04:35:35.001891: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
                                                      runs/expID8853000_TRAINode_ns:300000_ba:600_ode-units:255_gru-uts:0_lats:70_rec-lay:2_solver:euler_seed:6001_optim:adamax_stackin:1['ode_rnn', 'ode_rnn', 'ode_rnn']_ODEws_BN_rs
  0%|          | 0/15 [00:15<?, ?trial/s, best loss=?]run_models.py --niters 20 -n 300000 -validn 60000 -b 600 -BN --resnet --lr 0.0084761 -ODEws --ode-rnn -g 0 --stack-order ode_rnn ode_rnn ode_rnn --ode-type linear --rnn-cell star --ode-method euler --random-seed 6001 --optimizer adamax --num-search 15 --hparams lr

                                                      0.8713132400430571
  0%|          | 0/15 [1:16:23<?, ?trial/s, best loss=?]                                                         at step 
  0%|          | 0/15 [1:16:23<?, ?trial/s, best loss=?]                                                        5151600
  0%|          | 0/15 [1:16:23<?, ?trial/s, best loss=?]                                                        {'loss': 0.1286867599569429, 'loss_variance': nan, 'status': 'ok', 'num_seeds': 1, 'best_acc': 0.8713132400430571, 'best_peak_step': 5151600, 'best_steps': [5151600]}
  0%|          | 0/15 [1:16:23<?, ?trial/s, best loss=?]  7%|▋         | 1/15 [1:16:23<17:49:33, 4583.81s/trial, best loss: 0.1286867599569429]/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/training.py:180: RuntimeWarning: invalid value encountered in true_divide
  var_test_acc = sum((abs(Test_acc - mean_test_acc)**2)/(num_seeds-1))

/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/training.py:183: RuntimeWarning: invalid value encountered in true_divide
  var_best_test_acc = sum((abs(Best_test_acc - mean_best_test_acc)**2)/(num_seeds-1))

/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/training.py:188: RuntimeWarning: invalid value encountered in true_divide
  var_train_acc = sum((abs(Train_acc - mean_train_acc)**2)/(num_seeds-1))

build_posterior_wrapper took 0.001386 seconds

TPE using 1/1 trials with best loss 0.128687

                                                                                       Testing hyperparameters:
  7%|▋         | 1/15 [1:16:23<17:49:33, 4583.81s/trial, best loss: 0.1286867599569429]                                                                                       lr : 0.0012344842247950353
  7%|▋         | 1/15 [1:16:23<17:49:33, 4583.81s/trial, best loss: 0.1286867599569429]                                                                                       Trainingdataset:
  7%|▋         | 1/15 [1:16:23<17:49:33, 4583.81s/trial, best loss: 0.1286867599569429]                                                                                       Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

  7%|▋         | 1/15 [1:16:23<17:49:33, 4583.81s/trial, best loss: 0.1286867599569429]                                                                                       Using Evaluationdataset:
  7%|▋         | 1/15 [1:16:23<17:49:33, 4583.81s/trial, best loss: 0.1286867599569429]                                                                                       Dataset Crops
    Number of datapoints: 55740
    Root Location: data/Crops
    Reduce: average

  7%|▋         | 1/15 [1:16:23<17:49:33, 4583.81s/trial, best loss: 0.1286867599569429]                                                                                       Warning, the specified stacking order is not the same length as the number of stacked layers, taking stack-order as reference.
  7%|▋         | 1/15 [1:16:23<17:49:33, 4583.81s/trial, best loss: 0.1286867599569429]                                                                                       runs/expID2265000_TRAINode_ns:300000_ba:600_ode-units:255_gru-uts:0_lats:70_rec-lay:2_solver:euler_seed:6001_optim:adamax_stackin:1['ode_rnn', 'ode_rnn', 'ode_rnn']_ODEws_BN_rs
  7%|▋         | 1/15 [1:16:23<17:49:33, 4583.81s/trial, best loss: 0.1286867599569429]run_models.py --niters 20 -n 300000 -validn 60000 -b 600 -BN --resnet --lr 0.0084761 -ODEws --ode-rnn -g 0 --stack-order ode_rnn ode_rnn ode_rnn --ode-type linear --rnn-cell star --ode-method euler --random-seed 6001 --optimizer adamax --num-search 15 --hparams lr

run_models.py --niters 20 -n 300000 -validn 60000 -b 600 -BN --resnet --lr 0.0084761 -ODEws --ode-rnn -g 0 --stack-order ode_rnn ode_rnn ode_rnn --ode-type linear --rnn-cell star --ode-method euler --random-seed 6001 --optimizer adamax --num-search 15 --hparams lr

                                                                                       0.8646932185145317
  7%|▋         | 1/15 [2:32:40<17:49:33, 4583.81s/trial, best loss: 0.1286867599569429]                                                                                        at step 
  7%|▋         | 1/15 [2:32:40<17:49:33, 4583.81s/trial, best loss: 0.1286867599569429]                                                                                       5628600
  7%|▋         | 1/15 [2:32:40<17:49:33, 4583.81s/trial, best loss: 0.1286867599569429]                                                                                       {'loss': 0.13530678148546826, 'loss_variance': nan, 'status': 'ok', 'num_seeds': 1, 'best_acc': 0.8646932185145317, 'best_peak_step': 5628600, 'best_steps': [5628600]}
  7%|▋         | 1/15 [2:32:40<17:49:33, 4583.81s/trial, best loss: 0.1286867599569429] 13%|█▎        | 2/15 [2:32:40<16:32:41, 4581.67s/trial, best loss: 0.1286867599569429]build_posterior_wrapper took 0.001768 seconds

build_posterior_wrapper took 0.001768 seconds

TPE using 2/2 trials with best loss 0.128687

TPE using 2/2 trials with best loss 0.128687

                                                                                       Testing hyperparameters:
 13%|█▎        | 2/15 [2:32:40<16:32:41, 4581.67s/trial, best loss: 0.1286867599569429]                                                                                       lr : 0.001428049695359857
 13%|█▎        | 2/15 [2:32:40<16:32:41, 4581.67s/trial, best loss: 0.1286867599569429]                                                                                       Trainingdataset:
 13%|█▎        | 2/15 [2:32:40<16:32:41, 4581.67s/trial, best loss: 0.1286867599569429]                                                                                       Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

 13%|█▎        | 2/15 [2:32:40<16:32:41, 4581.67s/trial, best loss: 0.1286867599569429]                                                                                       Using Evaluationdataset:
 13%|█▎        | 2/15 [2:32:40<16:32:41, 4581.67s/trial, best loss: 0.1286867599569429]                                                                                       Dataset Crops
    Number of datapoints: 55740
    Root Location: data/Crops
    Reduce: average

 13%|█▎        | 2/15 [2:32:40<16:32:41, 4581.67s/trial, best loss: 0.1286867599569429]                                                                                       Warning, the specified stacking order is not the same length as the number of stacked layers, taking stack-order as reference.
 13%|█▎        | 2/15 [2:32:40<16:32:41, 4581.67s/trial, best loss: 0.1286867599569429]                                                                                       runs/expID2741000_TRAINode_ns:300000_ba:600_ode-units:255_gru-uts:0_lats:70_rec-lay:2_solver:euler_seed:6001_optim:adamax_stackin:1['ode_rnn', 'ode_rnn', 'ode_rnn']_ODEws_BN_rs
 13%|█▎        | 2/15 [2:32:40<16:32:41, 4581.67s/trial, best loss: 0.1286867599569429]run_models.py --niters 20 -n 300000 -validn 60000 -b 600 -BN --resnet --lr 0.0084761 -ODEws --ode-rnn -g 0 --stack-order ode_rnn ode_rnn ode_rnn --ode-type linear --rnn-cell star --ode-method euler --random-seed 6001 --optimizer adamax --num-search 15 --hparams lr

run_models.py --niters 20 -n 300000 -validn 60000 -b 600 -BN --resnet --lr 0.0084761 -ODEws --ode-rnn -g 0 --stack-order ode_rnn ode_rnn ode_rnn --ode-type linear --rnn-cell star --ode-method euler --random-seed 6001 --optimizer adamax --num-search 15 --hparams lr

run_models.py --niters 20 -n 300000 -validn 60000 -b 600 -BN --resnet --lr 0.0084761 -ODEws --ode-rnn -g 0 --stack-order ode_rnn ode_rnn ode_rnn --ode-type linear --rnn-cell star --ode-method euler --random-seed 6001 --optimizer adamax --num-search 15 --hparams lr

