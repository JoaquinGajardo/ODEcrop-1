Lmod has detected the following error: The following module(s) are unknown:
"cuda/10.0.13" "pytorch/1.4.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/10.0.13" "pytorch/1.4.0"



Couldn't import umap
I'm counting gpu's:  1
Means I will train  1  models, with different random seeds
My Devices:  ['cuda:0']
Sampling dataset of 300000 training examples
  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]                                                     Testing hyperparameters:
  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]                                                     lr : 0.02307043413263282
  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]                                                     Trainingdataset:
  0%|          | 0/5 [00:05<?, ?trial/s, best loss=?]                                                     Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

  0%|          | 0/5 [00:05<?, ?trial/s, best loss=?]                                                     Using Evaluationdataset:
  0%|          | 0/5 [00:05<?, ?trial/s, best loss=?]                                                     Dataset Crops
    Number of datapoints: 55740
    Root Location: data/Crops
    Reduce: average

  0%|          | 0/5 [00:05<?, ?trial/s, best loss=?]                                                     Warning, the specified stacking order is not the same length as the number of stacked layers, taking stack-order as reference.
  0%|          | 0/5 [00:05<?, ?trial/s, best loss=?]2020-05-02 14:05:21.510154: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/extras/CUPTI/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-05-02 14:05:21.510505: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/extras/CUPTI/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-05-02 14:05:21.510521: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
                                                     runs/expID1448000_TRAINode_ns:300000_ba:600_ode-units:255_gru-uts:100_lats:70_rec-lay:2_solver:euler_seed:6001_optim:adamax_stackin:2None_BN
  0%|          | 0/5 [00:09<?, ?trial/s, best loss=?]run_models.py --niters 25 -n 300000 -validn 60000 -b 600 --ode-rnn --rnn-cell gru --random-seed 6001 --num-search 5 --num-seeds 1 --lr 0.00762 -g 100 -l 70 -u 255 --topper -BN --stacking 2 --hparams lr

                                                     0.8747219232149265
  0%|          | 0/5 [1:27:33<?, ?trial/s, best loss=?]                                                        at step 
  0%|          | 0/5 [1:27:33<?, ?trial/s, best loss=?]                                                       4006800
  0%|          | 0/5 [1:27:33<?, ?trial/s, best loss=?]                                                       {'loss': 0.12527807678507352, 'loss_variance': nan, 'status': 'ok', 'num_seeds': 1, 'best_acc': 0.8747219232149265, 'best_peak_step': 4006800, 'best_steps': [4006800]}
  0%|          | 0/5 [1:27:33<?, ?trial/s, best loss=?] 20%|██        | 1/5 [1:27:33<5:50:13, 5253.40s/trial, best loss: 0.12527807678507352]/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/training.py:180: RuntimeWarning: invalid value encountered in true_divide
  var_test_acc = sum((abs(Test_acc - mean_test_acc)**2)/(num_seeds-1))

/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/training.py:183: RuntimeWarning: invalid value encountered in true_divide
  var_best_test_acc = sum((abs(Best_test_acc - mean_best_test_acc)**2)/(num_seeds-1))

/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/training.py:188: RuntimeWarning: invalid value encountered in true_divide
  var_train_acc = sum((abs(Train_acc - mean_train_acc)**2)/(num_seeds-1))

build_posterior_wrapper took 0.001347 seconds

TPE using 1/1 trials with best loss 0.125278

                                                                                      Testing hyperparameters:
 20%|██        | 1/5 [1:27:33<5:50:13, 5253.40s/trial, best loss: 0.12527807678507352]                                                                                      lr : 0.000414838995026309
 20%|██        | 1/5 [1:27:33<5:50:13, 5253.40s/trial, best loss: 0.12527807678507352]                                                                                      Trainingdataset:
 20%|██        | 1/5 [1:27:33<5:50:13, 5253.40s/trial, best loss: 0.12527807678507352]                                                                                      Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

 20%|██        | 1/5 [1:27:33<5:50:13, 5253.40s/trial, best loss: 0.12527807678507352]                                                                                      Using Evaluationdataset:
 20%|██        | 1/5 [1:27:33<5:50:13, 5253.40s/trial, best loss: 0.12527807678507352]                                                                                      Dataset Crops
    Number of datapoints: 55740
    Root Location: data/Crops
    Reduce: average

 20%|██        | 1/5 [1:27:33<5:50:13, 5253.40s/trial, best loss: 0.12527807678507352]                                                                                      Warning, the specified stacking order is not the same length as the number of stacked layers, taking stack-order as reference.
 20%|██        | 1/5 [1:27:33<5:50:13, 5253.40s/trial, best loss: 0.12527807678507352]                                                                                      runs/expID251000_TRAINode_ns:300000_ba:600_ode-units:255_gru-uts:100_lats:70_rec-lay:2_solver:euler_seed:6001_optim:adamax_stackin:2None_BN
 20%|██        | 1/5 [1:27:33<5:50:13, 5253.40s/trial, best loss: 0.12527807678507352]run_models.py --niters 25 -n 300000 -validn 60000 -b 600 --ode-rnn --rnn-cell gru --random-seed 6001 --num-search 5 --num-seeds 1 --lr 0.00762 -g 100 -l 70 -u 255 --topper -BN --stacking 2 --hparams lr

run_models.py --niters 25 -n 300000 -validn 60000 -b 600 --ode-rnn --rnn-cell gru --random-seed 6001 --num-search 5 --num-seeds 1 --lr 0.00762 -g 100 -l 70 -u 255 --topper -BN --stacking 2 --hparams lr

                                                                                      0.8566738428417653
 20%|██        | 1/5 [2:55:36<5:50:13, 5253.40s/trial, best loss: 0.12527807678507352]                                                                                       at step 
 20%|██        | 1/5 [2:55:36<5:50:13, 5253.40s/trial, best loss: 0.12527807678507352]                                                                                      6582600
 20%|██        | 1/5 [2:55:36<5:50:13, 5253.40s/trial, best loss: 0.12527807678507352]                                                                                      {'loss': 0.1433261571582347, 'loss_variance': nan, 'status': 'ok', 'num_seeds': 1, 'best_acc': 0.8566738428417653, 'best_peak_step': 6582600, 'best_steps': [6582600]}
 20%|██        | 1/5 [2:55:36<5:50:13, 5253.40s/trial, best loss: 0.12527807678507352] 40%|████      | 2/5 [2:55:36<4:23:07, 5262.39s/trial, best loss: 0.12527807678507352]build_posterior_wrapper took 0.001710 seconds

build_posterior_wrapper took 0.001710 seconds

TPE using 2/2 trials with best loss 0.125278

TPE using 2/2 trials with best loss 0.125278

                                                                                      Testing hyperparameters:
 40%|████      | 2/5 [2:55:36<4:23:07, 5262.39s/trial, best loss: 0.12527807678507352]                                                                                      lr : 0.00039508151940425185
 40%|████      | 2/5 [2:55:36<4:23:07, 5262.39s/trial, best loss: 0.12527807678507352]                                                                                      Trainingdataset:
 40%|████      | 2/5 [2:55:36<4:23:07, 5262.39s/trial, best loss: 0.12527807678507352]                                                                                      Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

 40%|████      | 2/5 [2:55:36<4:23:07, 5262.39s/trial, best loss: 0.12527807678507352]                                                                                      Using Evaluationdataset:
 40%|████      | 2/5 [2:55:36<4:23:07, 5262.39s/trial, best loss: 0.12527807678507352]                                                                                      Dataset Crops
    Number of datapoints: 55740
    Root Location: data/Crops
    Reduce: average

 40%|████      | 2/5 [2:55:36<4:23:07, 5262.39s/trial, best loss: 0.12527807678507352]                                                                                      Warning, the specified stacking order is not the same length as the number of stacked layers, taking stack-order as reference.
 40%|████      | 2/5 [2:55:36<4:23:07, 5262.39s/trial, best loss: 0.12527807678507352]                                                                                      runs/expID8615000_TRAINode_ns:300000_ba:600_ode-units:255_gru-uts:100_lats:70_rec-lay:2_solver:euler_seed:6001_optim:adamax_stackin:2None_BN
 40%|████      | 2/5 [2:55:36<4:23:07, 5262.39s/trial, best loss: 0.12527807678507352]run_models.py --niters 25 -n 300000 -validn 60000 -b 600 --ode-rnn --rnn-cell gru --random-seed 6001 --num-search 5 --num-seeds 1 --lr 0.00762 -g 100 -l 70 -u 255 --topper -BN --stacking 2 --hparams lr

run_models.py --niters 25 -n 300000 -validn 60000 -b 600 --ode-rnn --rnn-cell gru --random-seed 6001 --num-search 5 --num-seeds 1 --lr 0.00762 -g 100 -l 70 -u 255 --topper -BN --stacking 2 --hparams lr

run_models.py --niters 25 -n 300000 -validn 60000 -b 600 --ode-rnn --rnn-cell gru --random-seed 6001 --num-search 5 --num-seeds 1 --lr 0.00762 -g 100 -l 70 -u 255 --topper -BN --stacking 2 --hparams lr

                                                                                      0.8557947613921779
 40%|████      | 2/5 [4:25:17<4:23:07, 5262.39s/trial, best loss: 0.12527807678507352]                                                                                       at step 
 40%|████      | 2/5 [4:25:17<4:23:07, 5262.39s/trial, best loss: 0.12527807678507352]                                                                                      7059600
 40%|████      | 2/5 [4:25:17<4:23:07, 5262.39s/trial, best loss: 0.12527807678507352]                                                                                      {'loss': 0.14420523860782208, 'loss_variance': nan, 'status': 'ok', 'num_seeds': 1, 'best_acc': 0.8557947613921779, 'best_peak_step': 7059600, 'best_steps': [7059600]}
 40%|████      | 2/5 [4:25:17<4:23:07, 5262.39s/trial, best loss: 0.12527807678507352] 60%|██████    | 3/5 [4:25:17<2:56:36, 5298.02s/trial, best loss: 0.12527807678507352]build_posterior_wrapper took 0.001877 seconds

build_posterior_wrapper took 0.001877 seconds

build_posterior_wrapper took 0.001877 seconds

TPE using 3/3 trials with best loss 0.125278

TPE using 3/3 trials with best loss 0.125278

TPE using 3/3 trials with best loss 0.125278

                                                                                      Testing hyperparameters:
 60%|██████    | 3/5 [4:25:17<2:56:36, 5298.02s/trial, best loss: 0.12527807678507352]                                                                                      lr : 0.0005853693469857151
 60%|██████    | 3/5 [4:25:17<2:56:36, 5298.02s/trial, best loss: 0.12527807678507352]                                                                                      Trainingdataset:
 60%|██████    | 3/5 [4:25:18<2:56:36, 5298.02s/trial, best loss: 0.12527807678507352]                                                                                      Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

 60%|██████    | 3/5 [4:25:18<2:56:36, 5298.02s/trial, best loss: 0.12527807678507352]                                                                                      Using Evaluationdataset:
 60%|██████    | 3/5 [4:25:18<2:56:36, 5298.02s/trial, best loss: 0.12527807678507352]                                                                                      Dataset Crops
    Number of datapoints: 55740
    Root Location: data/Crops
    Reduce: average

 60%|██████    | 3/5 [4:25:18<2:56:36, 5298.02s/trial, best loss: 0.12527807678507352]                                                                                      Warning, the specified stacking order is not the same length as the number of stacked layers, taking stack-order as reference.
 60%|██████    | 3/5 [4:25:18<2:56:36, 5298.02s/trial, best loss: 0.12527807678507352]                                                                                      runs/expID6500000_TRAINode_ns:300000_ba:600_ode-units:255_gru-uts:100_lats:70_rec-lay:2_solver:euler_seed:6001_optim:adamax_stackin:2None_BN
 60%|██████    | 3/5 [4:25:18<2:56:36, 5298.02s/trial, best loss: 0.12527807678507352]run_models.py --niters 25 -n 300000 -validn 60000 -b 600 --ode-rnn --rnn-cell gru --random-seed 6001 --num-search 5 --num-seeds 1 --lr 0.00762 -g 100 -l 70 -u 255 --topper -BN --stacking 2 --hparams lr

run_models.py --niters 25 -n 300000 -validn 60000 -b 600 --ode-rnn --rnn-cell gru --random-seed 6001 --num-search 5 --num-seeds 1 --lr 0.00762 -g 100 -l 70 -u 255 --topper -BN --stacking 2 --hparams lr

run_models.py --niters 25 -n 300000 -validn 60000 -b 600 --ode-rnn --rnn-cell gru --random-seed 6001 --num-search 5 --num-seeds 1 --lr 0.00762 -g 100 -l 70 -u 255 --topper -BN --stacking 2 --hparams lr

run_models.py --niters 25 -n 300000 -validn 60000 -b 600 --ode-rnn --rnn-cell gru --random-seed 6001 --num-search 5 --num-seeds 1 --lr 0.00762 -g 100 -l 70 -u 255 --topper -BN --stacking 2 --hparams lr

                                                                                      0.8619124506637962
 60%|██████    | 3/5 [5:55:24<2:56:36, 5298.02s/trial, best loss: 0.12527807678507352]                                                                                       at step 
 60%|██████    | 3/5 [5:55:24<2:56:36, 5298.02s/trial, best loss: 0.12527807678507352]                                                                                      7059600
 60%|██████    | 3/5 [5:55:24<2:56:36, 5298.02s/trial, best loss: 0.12527807678507352]                                                                                      {'loss': 0.13808754933620382, 'loss_variance': nan, 'status': 'ok', 'num_seeds': 1, 'best_acc': 0.8619124506637962, 'best_peak_step': 7059600, 'best_steps': [7059600]}
 60%|██████    | 3/5 [5:55:24<2:56:36, 5298.02s/trial, best loss: 0.12527807678507352] 80%|████████  | 4/5 [5:55:24<1:28:50, 5330.55s/trial, best loss: 0.12527807678507352]build_posterior_wrapper took 0.001890 seconds

build_posterior_wrapper took 0.001890 seconds

build_posterior_wrapper took 0.001890 seconds

build_posterior_wrapper took 0.001890 seconds

TPE using 4/4 trials with best loss 0.125278

TPE using 4/4 trials with best loss 0.125278

TPE using 4/4 trials with best loss 0.125278

TPE using 4/4 trials with best loss 0.125278

                                                                                      Testing hyperparameters:
 80%|████████  | 4/5 [5:55:24<1:28:50, 5330.55s/trial, best loss: 0.12527807678507352]                                                                                      lr : 0.0002522364784034391
 80%|████████  | 4/5 [5:55:24<1:28:50, 5330.55s/trial, best loss: 0.12527807678507352]                                                                                      Trainingdataset:
 80%|████████  | 4/5 [5:55:24<1:28:50, 5330.55s/trial, best loss: 0.12527807678507352]                                                                                      Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

 80%|████████  | 4/5 [5:55:24<1:28:50, 5330.55s/trial, best loss: 0.12527807678507352]                                                                                      Using Evaluationdataset:
 80%|████████  | 4/5 [5:55:24<1:28:50, 5330.55s/trial, best loss: 0.12527807678507352]                                                                                      Dataset Crops
    Number of datapoints: 55740
    Root Location: data/Crops
    Reduce: average

 80%|████████  | 4/5 [5:55:24<1:28:50, 5330.55s/trial, best loss: 0.12527807678507352]                                                                                      Warning, the specified stacking order is not the same length as the number of stacked layers, taking stack-order as reference.
 80%|████████  | 4/5 [5:55:24<1:28:50, 5330.55s/trial, best loss: 0.12527807678507352]                                                                                      runs/expID1237000_TRAINode_ns:300000_ba:600_ode-units:255_gru-uts:100_lats:70_rec-lay:2_solver:euler_seed:6001_optim:adamax_stackin:2None_BN
 80%|████████  | 4/5 [5:55:24<1:28:50, 5330.55s/trial, best loss: 0.12527807678507352]run_models.py --niters 25 -n 300000 -validn 60000 -b 600 --ode-rnn --rnn-cell gru --random-seed 6001 --num-search 5 --num-seeds 1 --lr 0.00762 -g 100 -l 70 -u 255 --topper -BN --stacking 2 --hparams lr

run_models.py --niters 25 -n 300000 -validn 60000 -b 600 --ode-rnn --rnn-cell gru --random-seed 6001 --num-search 5 --num-seeds 1 --lr 0.00762 -g 100 -l 70 -u 255 --topper -BN --stacking 2 --hparams lr

run_models.py --niters 25 -n 300000 -validn 60000 -b 600 --ode-rnn --rnn-cell gru --random-seed 6001 --num-search 5 --num-seeds 1 --lr 0.00762 -g 100 -l 70 -u 255 --topper -BN --stacking 2 --hparams lr

run_models.py --niters 25 -n 300000 -validn 60000 -b 600 --ode-rnn --rnn-cell gru --random-seed 6001 --num-search 5 --num-seeds 1 --lr 0.00762 -g 100 -l 70 -u 255 --topper -BN --stacking 2 --hparams lr

run_models.py --niters 25 -n 300000 -validn 60000 -b 600 --ode-rnn --rnn-cell gru --random-seed 6001 --num-search 5 --num-seeds 1 --lr 0.00762 -g 100 -l 70 -u 255 --topper -BN --stacking 2 --hparams lr

                                                                                      0.8495873699318264
 80%|████████  | 4/5 [7:23:16<1:28:50, 5330.55s/trial, best loss: 0.12527807678507352]                                                                                       at step 
 80%|████████  | 4/5 [7:23:16<1:28:50, 5330.55s/trial, best loss: 0.12527807678507352]                                                                                      7155000
 80%|████████  | 4/5 [7:23:16<1:28:50, 5330.55s/trial, best loss: 0.12527807678507352]                                                                                      {'loss': 0.15041263006817363, 'loss_variance': nan, 'status': 'ok', 'num_seeds': 1, 'best_acc': 0.8495873699318264, 'best_peak_step': 7155000, 'best_steps': [7155000]}
 80%|████████  | 4/5 [7:23:16<1:28:50, 5330.55s/trial, best loss: 0.12527807678507352]100%|██████████| 5/5 [7:23:16<00:00, 5312.93s/trial, best loss: 0.12527807678507352]  100%|██████████| 5/5 [7:23:16<00:00, 5319.24s/trial, best loss: 0.12527807678507352]
ODE-RNN  True
Classic-RNN:  False
Stacked layers:  2
Stacked layers:  None
ODE-type:  linear
RNN-cell:  gru
Weight-sharing ODE:  False
Weight-sharing RNN:  False
Using BN:  True
defaut adapted LR's!!
Used Optimizer: adamax
Used Ode-Solver euler

---------------------------------------------------------------------------------------------------------------------------------------------
TRIAL PROTOCOL:
---------------------------------------------------------------------------------------------------------------------------------------------
Trial: 0001  |  #runs: 1  |  Mean Acc.: 87.472 %  |  Std: nan %  |  Best Acc.: 87.472 % (Peak: 4006800 samples)  |  Hparams: {'lr': [0.02307043413263282]}  |
Trial: 0002  |  #runs: 1  |  Mean Acc.: 85.667 %  |  Std: nan %  |  Best Acc.: 85.667 % (Peak: 6582600 samples)  |  Hparams: {'lr': [0.000414838995026309]}  |
Trial: 0003  |  #runs: 1  |  Mean Acc.: 85.579 %  |  Std: nan %  |  Best Acc.: 85.579 % (Peak: 7059600 samples)  |  Hparams: {'lr': [0.00039508151940425185]}  |
Trial: 0004  |  #runs: 1  |  Mean Acc.: 86.191 %  |  Std: nan %  |  Best Acc.: 86.191 % (Peak: 7059600 samples)  |  Hparams: {'lr': [0.0005853693469857151]}  |
Trial: 0005  |  #runs: 1  |  Mean Acc.: 84.959 %  |  Std: nan %  |  Best Acc.: 84.959 % (Peak: 7155000 samples)  |  Hparams: {'lr': [0.0002522364784034391]}  |
---------------------------------------------------------------------------------------------------------------------------------------------
Best configuration mean: 87.472 % (+-nan) (best run: 87.472 %) , with Hyperparmeters: {'lr': [0.02307043413263282]}
---------------------------------------------------------------------------------------------------------------------------------------------
