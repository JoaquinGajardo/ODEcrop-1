Lmod has detected the following error: The following module(s) are unknown:
"cuda/10.0.13" "pytorch/1.4.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/10.0.13" "pytorch/1.4.0"



Couldn't import umap
I'm counting gpu's:  1
Means I will train  1  models, with different random seeds
My Devices:  ['cuda:0']
Sampling dataset of 300000 training examples
  0%|          | 0/4 [00:00<?, ?trial/s, best loss=?]                                                     Testing hyperparameters:
  0%|          | 0/4 [00:00<?, ?trial/s, best loss=?]                                                     batch_size : (450.0,)
  0%|          | 0/4 [00:00<?, ?trial/s, best loss=?]                                                     Trainingdataset:
  0%|          | 0/4 [00:03<?, ?trial/s, best loss=?]                                                     Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

  0%|          | 0/4 [00:03<?, ?trial/s, best loss=?]                                                     Using Evaluationdataset:
  0%|          | 0/4 [00:03<?, ?trial/s, best loss=?]                                                     Dataset Crops
    Number of datapoints: 55740
    Root Location: data/Crops
    Reduce: average

  0%|          | 0/4 [00:03<?, ?trial/s, best loss=?]2020-04-23 23:09:53.434503: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/extras/CUPTI/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-04-23 23:09:53.434649: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/extras/CUPTI/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-04-23 23:09:53.434662: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
                                                     runs/expID4897000_TRAINode_ns:300000_ba:450_ode-units:255_gru-uts:100_lats:70_rec-lay:2_solver:dopri5_seed:6001_optim:adaw_stackin:2
  0%|          | 0/4 [00:06<?, ?trial/s, best loss=?]run_models.py --niters 30 -n 300000 -validn 60000 -b 700 --lr 0.0084761 --ode-rnn --stacking 2 --ode-type linear --rnn-cell gru --ode-method dopri5 --random-seed 6001 --optimizer adaw --num-search 4 --num-seeds 1 --hparams batch_size

                                                     0.8531216361679225
  0%|          | 0/4 [6:21:11<?, ?trial/s, best loss=?]                                                        at step 
  0%|          | 0/4 [6:21:11<?, ?trial/s, best loss=?]                                                       5942700
  0%|          | 0/4 [6:21:11<?, ?trial/s, best loss=?]                                                       {'loss': 0.14687836383207753, 'loss_variance': nan, 'status': 'ok', 'num_seeds': 1, 'best_acc': 0.8531216361679225, 'best_peak_step': 5942700, 'best_steps': [5942700]}
  0%|          | 0/4 [6:21:11<?, ?trial/s, best loss=?] 25%|██▌       | 1/4 [6:21:11<19:03:33, 22871.33s/trial, best loss: 0.14687836383207753]/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/training.py:168: RuntimeWarning: invalid value encountered in true_divide
  var_test_acc = sum((abs(Test_acc - mean_test_acc)**2)/(num_seeds-1))

/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/training.py:171: RuntimeWarning: invalid value encountered in true_divide
  var_best_test_acc = sum((abs(Best_test_acc - mean_best_test_acc)**2)/(num_seeds-1))

/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/training.py:176: RuntimeWarning: invalid value encountered in true_divide
  var_train_acc = sum((abs(Train_acc - mean_train_acc)**2)/(num_seeds-1))

build_posterior_wrapper took 0.001426 seconds

TPE using 1/1 trials with best loss 0.146878

                                                                                        Testing hyperparameters:
 25%|██▌       | 1/4 [6:21:11<19:03:33, 22871.33s/trial, best loss: 0.14687836383207753]                                                                                        batch_size : (300.0,)
 25%|██▌       | 1/4 [6:21:11<19:03:33, 22871.33s/trial, best loss: 0.14687836383207753]                                                                                        Trainingdataset:
 25%|██▌       | 1/4 [6:21:11<19:03:33, 22871.33s/trial, best loss: 0.14687836383207753]                                                                                        Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

 25%|██▌       | 1/4 [6:21:11<19:03:33, 22871.33s/trial, best loss: 0.14687836383207753]                                                                                        Using Evaluationdataset:
 25%|██▌       | 1/4 [6:21:11<19:03:33, 22871.33s/trial, best loss: 0.14687836383207753]                                                                                        Dataset Crops
    Number of datapoints: 55740
    Root Location: data/Crops
    Reduce: average

 25%|██▌       | 1/4 [6:21:11<19:03:33, 22871.33s/trial, best loss: 0.14687836383207753]                                                                                        runs/expID5315000_TRAINode_ns:300000_ba:300_ode-units:255_gru-uts:100_lats:70_rec-lay:2_solver:dopri5_seed:6001_optim:adaw_stackin:2
 25%|██▌       | 1/4 [6:21:11<19:03:33, 22871.33s/trial, best loss: 0.14687836383207753]run_models.py --niters 30 -n 300000 -validn 60000 -b 700 --lr 0.0084761 --ode-rnn --stacking 2 --ode-type linear --rnn-cell gru --ode-method dopri5 --random-seed 6001 --optimizer adaw --num-search 4 --num-seeds 1 --hparams batch_size

run_models.py --niters 30 -n 300000 -validn 60000 -b 700 --lr 0.0084761 --ode-rnn --stacking 2 --ode-type linear --rnn-cell gru --ode-method dopri5 --random-seed 6001 --optimizer adaw --num-search 4 --num-seeds 1 --hparams batch_size

                                                                                        0.852134912091855
 25%|██▌       | 1/4 [16:32:14<19:03:33, 22871.33s/trial, best loss: 0.14687836383207753]                                                                                          at step 
 25%|██▌       | 1/4 [16:32:14<19:03:33, 22871.33s/trial, best loss: 0.14687836383207753]                                                                                         7081800
 25%|██▌       | 1/4 [16:32:14<19:03:33, 22871.33s/trial, best loss: 0.14687836383207753]                                                                                         {'loss': 0.147865087908145, 'loss_variance': nan, 'status': 'ok', 'num_seeds': 1, 'best_acc': 0.852134912091855, 'best_peak_step': 7081800, 'best_steps': [7081800]}
 25%|██▌       | 1/4 [16:32:14<19:03:33, 22871.33s/trial, best loss: 0.14687836383207753] 50%|█████     | 2/4 [16:32:14<15:00:17, 27008.77s/trial, best loss: 0.14687836383207753]build_posterior_wrapper took 0.003968 seconds

build_posterior_wrapper took 0.003968 seconds

TPE using 2/2 trials with best loss 0.146878

TPE using 2/2 trials with best loss 0.146878

                                                                                         Testing hyperparameters:
 50%|█████     | 2/4 [16:32:14<15:00:17, 27008.77s/trial, best loss: 0.14687836383207753]                                                                                         batch_size : (450.0,)
 50%|█████     | 2/4 [16:32:14<15:00:17, 27008.77s/trial, best loss: 0.14687836383207753]                                                                                         Trainingdataset:
 50%|█████     | 2/4 [16:32:14<15:00:17, 27008.77s/trial, best loss: 0.14687836383207753]                                                                                         Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

 50%|█████     | 2/4 [16:32:14<15:00:17, 27008.77s/trial, best loss: 0.14687836383207753]                                                                                         Using Evaluationdataset:
 50%|█████     | 2/4 [16:32:14<15:00:17, 27008.77s/trial, best loss: 0.14687836383207753]                                                                                         Dataset Crops
    Number of datapoints: 55740
    Root Location: data/Crops
    Reduce: average

 50%|█████     | 2/4 [16:32:14<15:00:17, 27008.77s/trial, best loss: 0.14687836383207753]                                                                                         runs/expID3784000_TRAINode_ns:300000_ba:450_ode-units:255_gru-uts:100_lats:70_rec-lay:2_solver:dopri5_seed:6001_optim:adaw_stackin:2
 50%|█████     | 2/4 [16:32:14<15:00:17, 27008.77s/trial, best loss: 0.14687836383207753]run_models.py --niters 30 -n 300000 -validn 60000 -b 700 --lr 0.0084761 --ode-rnn --stacking 2 --ode-type linear --rnn-cell gru --ode-method dopri5 --random-seed 6001 --optimizer adaw --num-search 4 --num-seeds 1 --hparams batch_size

run_models.py --niters 30 -n 300000 -validn 60000 -b 700 --lr 0.0084761 --ode-rnn --stacking 2 --ode-type linear --rnn-cell gru --ode-method dopri5 --random-seed 6001 --optimizer adaw --num-search 4 --num-seeds 1 --hparams batch_size

run_models.py --niters 30 -n 300000 -validn 60000 -b 700 --lr 0.0084761 --ode-rnn --stacking 2 --ode-type linear --rnn-cell gru --ode-method dopri5 --random-seed 6001 --optimizer adaw --num-search 4 --num-seeds 1 --hparams batch_size

                                                                                         0.8531216361679225
 50%|█████     | 2/4 [23:28:29<15:00:17, 27008.77s/trial, best loss: 0.14687836383207753]                                                                                          at step 
 50%|█████     | 2/4 [23:28:29<15:00:17, 27008.77s/trial, best loss: 0.14687836383207753]                                                                                         5942700
 50%|█████     | 2/4 [23:28:29<15:00:17, 27008.77s/trial, best loss: 0.14687836383207753]                                                                                         {'loss': 0.14687836383207753, 'loss_variance': nan, 'status': 'ok', 'num_seeds': 1, 'best_acc': 0.8531216361679225, 'best_peak_step': 5942700, 'best_steps': [5942700]}
 50%|█████     | 2/4 [23:28:29<15:00:17, 27008.77s/trial, best loss: 0.14687836383207753] 75%|███████▌  | 3/4 [23:28:29<7:19:58, 26398.80s/trial, best loss: 0.14687836383207753] build_posterior_wrapper took 0.004778 seconds

build_posterior_wrapper took 0.004778 seconds

build_posterior_wrapper took 0.004778 seconds

TPE using 3/3 trials with best loss 0.146878

TPE using 3/3 trials with best loss 0.146878

TPE using 3/3 trials with best loss 0.146878

                                                                                        Testing hyperparameters:
 75%|███████▌  | 3/4 [23:28:29<7:19:58, 26398.80s/trial, best loss: 0.14687836383207753]                                                                                        batch_size : (890.0,)
 75%|███████▌  | 3/4 [23:28:29<7:19:58, 26398.80s/trial, best loss: 0.14687836383207753]                                                                                        Trainingdataset:
 75%|███████▌  | 3/4 [23:28:29<7:19:58, 26398.80s/trial, best loss: 0.14687836383207753]                                                                                        Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

 75%|███████▌  | 3/4 [23:28:29<7:19:58, 26398.80s/trial, best loss: 0.14687836383207753]                                                                                        Using Evaluationdataset:
 75%|███████▌  | 3/4 [23:28:29<7:19:58, 26398.80s/trial, best loss: 0.14687836383207753]                                                                                        Dataset Crops
    Number of datapoints: 55740
    Root Location: data/Crops
    Reduce: average

 75%|███████▌  | 3/4 [23:28:29<7:19:58, 26398.80s/trial, best loss: 0.14687836383207753]                                                                                        runs/expID5680000_TRAINode_ns:300000_ba:890_ode-units:255_gru-uts:100_lats:70_rec-lay:2_solver:dopri5_seed:6001_optim:adaw_stackin:2
 75%|███████▌  | 3/4 [23:28:29<7:19:58, 26398.80s/trial, best loss: 0.14687836383207753]run_models.py --niters 30 -n 300000 -validn 60000 -b 700 --lr 0.0084761 --ode-rnn --stacking 2 --ode-type linear --rnn-cell gru --ode-method dopri5 --random-seed 6001 --optimizer adaw --num-search 4 --num-seeds 1 --hparams batch_size

run_models.py --niters 30 -n 300000 -validn 60000 -b 700 --lr 0.0084761 --ode-rnn --stacking 2 --ode-type linear --rnn-cell gru --ode-method dopri5 --random-seed 6001 --optimizer adaw --num-search 4 --num-seeds 1 --hparams batch_size

run_models.py --niters 30 -n 300000 -validn 60000 -b 700 --lr 0.0084761 --ode-rnn --stacking 2 --ode-type linear --rnn-cell gru --ode-method dopri5 --random-seed 6001 --optimizer adaw --num-search 4 --num-seeds 1 --hparams batch_size

run_models.py --niters 30 -n 300000 -validn 60000 -b 700 --lr 0.0084761 --ode-rnn --stacking 2 --ode-type linear --rnn-cell gru --ode-method dopri5 --random-seed 6001 --optimizer adaw --num-search 4 --num-seeds 1 --hparams batch_size

                                                                                        0.8534445640473628
 75%|███████▌  | 3/4 [27:15:15<7:19:58, 26398.80s/trial, best loss: 0.14687836383207753]                                                                                         at step 
 75%|███████▌  | 3/4 [27:15:15<7:19:58, 26398.80s/trial, best loss: 0.14687836383207753]                                                                                        6570870
 75%|███████▌  | 3/4 [27:15:15<7:19:58, 26398.80s/trial, best loss: 0.14687836383207753]                                                                                        {'loss': 0.1465554359526372, 'loss_variance': nan, 'status': 'ok', 'num_seeds': 1, 'best_acc': 0.8534445640473628, 'best_peak_step': 6570870, 'best_steps': [6570870]}
 75%|███████▌  | 3/4 [27:15:15<7:19:58, 26398.80s/trial, best loss: 0.14687836383207753]100%|██████████| 4/4 [27:15:15<00:00, 22560.84s/trial, best loss: 0.1465554359526372]   100%|██████████| 4/4 [27:15:15<00:00, 24528.82s/trial, best loss: 0.1465554359526372]
ODE-RNN  True
Classic-RNN:  False
Stacked layers:  2
ODE-type:  linear
RNN-cell:  gru
defaut adapted LR's!!
Used Optimizer: adaw
Used Ode-Solver dopri5

---------------------------------------------------------------------------------------------------------------------------------------------
TRIAL PROTOCOL:
---------------------------------------------------------------------------------------------------------------------------------------------
Trial: 0001  |  #runs: 1  |  Mean Acc.: 85.312 %  |  Std: nan %  |  Best Acc.: 85.312 % (Peak: 5942700 samples)  |  Hparams: {'batch_size': [450.0]}  |
Trial: 0002  |  #runs: 1  |  Mean Acc.: 85.213 %  |  Std: nan %  |  Best Acc.: 85.213 % (Peak: 7081800 samples)  |  Hparams: {'batch_size': [300.0]}  |
Trial: 0003  |  #runs: 1  |  Mean Acc.: 85.312 %  |  Std: nan %  |  Best Acc.: 85.312 % (Peak: 5942700 samples)  |  Hparams: {'batch_size': [450.0]}  |
Trial: 0004  |  #runs: 1  |  Mean Acc.: 85.344 %  |  Std: nan %  |  Best Acc.: 85.344 % (Peak: 6570870 samples)  |  Hparams: {'batch_size': [890.0]}  |
---------------------------------------------------------------------------------------------------------------------------------------------
Best configuration mean: 85.344 % (+-nan) (best run: 85.344 %) , with Hyperparmeters: {'batch_size': [890.0]}
---------------------------------------------------------------------------------------------------------------------------------------------
