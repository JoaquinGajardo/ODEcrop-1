Lmod has detected the following error: The following module(s) are unknown:
"cuda/10.0.13" "pytorch/1.4.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "cuda/10.0.13" "pytorch/1.4.0"



Couldn't import umap
I'm counting gpu's:  1
Means I will train  1  models, with different random seeds
My Devices:  ['cuda:0']
Sampling dataset of 300000 training examples
  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]                                                     Testing hyperparameters:
  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]                                                     batch_size : (330.0,)
  0%|          | 0/5 [00:00<?, ?trial/s, best loss=?]                                                     Trainingdataset:
  0%|          | 0/5 [00:04<?, ?trial/s, best loss=?]                                                     Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

  0%|          | 0/5 [00:04<?, ?trial/s, best loss=?]                                                     Using Evaluationdataset:
  0%|          | 0/5 [00:04<?, ?trial/s, best loss=?]                                                     Dataset Crops
    Number of datapoints: 55740
    Root Location: data/Crops
    Reduce: average

  0%|          | 0/5 [00:04<?, ?trial/s, best loss=?]2020-04-22 22:51:15.537152: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/extras/CUPTI/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-04-22 22:51:15.537308: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cluster/apps/lsf/10.1/linux3.10-glibc2.17-x86_64/lib:/cluster/apps/gcc-4.8.5/libpng-1.6.27-d6quyddan2eotsexesxufytusf27xxgz/lib:/cluster/apps/gcc-4.8.5/jpeg-9b-psjvucpx7xwkflb3meatuo6ugdtapkex/lib:/cluster/apps/gcc-4.8.5/nccl-2.4.8-1-xpkpjc3dfz3c5knwctwl5vcut2ahfrwe/lib:/cluster/apps/gcc-4.8.5/cudnn-7.6.4-3ddmfyxxx2gkzhrra44ir3h3ls6yeuwe/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/extras/CUPTI/lib64:/cluster/apps/gcc-4.8.5/cuda-10.1.243-7tq43deb5x4dbs4oe427w4zszno23q6r/lib64:/cluster/apps/gcc-4.8.5/openblas-0.2.19-w25ydbabttcfa6g76gejjkthcm3xcuv3/lib:/cluster/apps/python/3.7.4/x86_64/lib64
2020-04-22 22:51:15.537323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
                                                     runs/expID1138000_TRAINode_ns:300000_ba:330_ode-units:255_gru-uts:100_lats:177_rec-lay:2_solver:dopri5_seed:6001_optim:adamax_stackin:1
  0%|          | 0/5 [00:08<?, ?trial/s, best loss=?]run_models.py --niters 50 -n 300000 -validn 60000 -l 177 --ode-rnn --ode-type gru --rnn-cell lstm --ode-method dopri5 --random-seed 6001 --optimizer adamax --num-search 5 --num-seeds 1 --hparams batch_size

                                                     0.8665052027269465
  0%|          | 0/5 [6:14:22<?, ?trial/s, best loss=?]                                                        at step 
  0%|          | 0/5 [6:14:22<?, ?trial/s, best loss=?]                                                       8900100
  0%|          | 0/5 [6:14:22<?, ?trial/s, best loss=?]                                                       {'loss': 0.13349479727305347, 'loss_variance': nan, 'status': 'ok', 'num_seeds': 1, 'best_acc': 0.8665052027269465, 'best_peak_step': 8900100, 'best_steps': [8900100]}
  0%|          | 0/5 [6:14:22<?, ?trial/s, best loss=?] 20%|██        | 1/5 [6:14:22<24:57:29, 22462.47s/trial, best loss: 0.13349479727305347]/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/training.py:168: RuntimeWarning: invalid value encountered in true_divide
  var_test_acc = sum((abs(Test_acc - mean_test_acc)**2)/(num_seeds-1))

/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/training.py:171: RuntimeWarning: invalid value encountered in true_divide
  var_best_test_acc = sum((abs(Best_test_acc - mean_best_test_acc)**2)/(num_seeds-1))

/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod_hparam/lib/training.py:176: RuntimeWarning: invalid value encountered in true_divide
  var_train_acc = sum((abs(Train_acc - mean_train_acc)**2)/(num_seeds-1))

build_posterior_wrapper took 0.001410 seconds

TPE using 1/1 trials with best loss 0.133495

                                                                                        Testing hyperparameters:
 20%|██        | 1/5 [6:14:22<24:57:29, 22462.47s/trial, best loss: 0.13349479727305347]                                                                                        batch_size : (1010.0,)
 20%|██        | 1/5 [6:14:22<24:57:29, 22462.47s/trial, best loss: 0.13349479727305347]                                                                                        Trainingdataset:
 20%|██        | 1/5 [6:14:22<24:57:29, 22462.47s/trial, best loss: 0.13349479727305347]                                                                                        Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

 20%|██        | 1/5 [6:14:22<24:57:29, 22462.47s/trial, best loss: 0.13349479727305347]                                                                                        Using Evaluationdataset:
 20%|██        | 1/5 [6:14:22<24:57:29, 22462.47s/trial, best loss: 0.13349479727305347]                                                                                        Dataset Crops
    Number of datapoints: 55740
    Root Location: data/Crops
    Reduce: average

 20%|██        | 1/5 [6:14:22<24:57:29, 22462.47s/trial, best loss: 0.13349479727305347]                                                                                        runs/expID351000_TRAINode_ns:300000_ba:1010_ode-units:255_gru-uts:100_lats:177_rec-lay:2_solver:dopri5_seed:6001_optim:adamax_stackin:1
 20%|██        | 1/5 [6:14:22<24:57:29, 22462.47s/trial, best loss: 0.13349479727305347]run_models.py --niters 50 -n 300000 -validn 60000 -l 177 --ode-rnn --ode-type gru --rnn-cell lstm --ode-method dopri5 --random-seed 6001 --optimizer adamax --num-search 5 --num-seeds 1 --hparams batch_size

run_models.py --niters 50 -n 300000 -validn 60000 -l 177 --ode-rnn --ode-type gru --rnn-cell lstm --ode-method dopri5 --random-seed 6001 --optimizer adamax --num-search 5 --num-seeds 1 --hparams batch_size

                                                                                        0.8656081808396124
 20%|██        | 1/5 [8:29:30<24:57:29, 22462.47s/trial, best loss: 0.13349479727305347]                                                                                         at step 
 20%|██        | 1/5 [8:29:30<24:57:29, 22462.47s/trial, best loss: 0.13349479727305347]                                                                                        8923350
 20%|██        | 1/5 [8:29:30<24:57:29, 22462.47s/trial, best loss: 0.13349479727305347]                                                                                        {'loss': 0.13439181916038756, 'loss_variance': nan, 'status': 'ok', 'num_seeds': 1, 'best_acc': 0.8656081808396124, 'best_peak_step': 8923350, 'best_steps': [8923350]}
 20%|██        | 1/5 [8:29:30<24:57:29, 22462.47s/trial, best loss: 0.13349479727305347] 40%|████      | 2/5 [8:29:30<15:07:48, 18156.01s/trial, best loss: 0.13349479727305347]build_posterior_wrapper took 0.001982 seconds

build_posterior_wrapper took 0.001982 seconds

TPE using 2/2 trials with best loss 0.133495

TPE using 2/2 trials with best loss 0.133495

                                                                                        Testing hyperparameters:
 40%|████      | 2/5 [8:29:30<15:07:48, 18156.01s/trial, best loss: 0.13349479727305347]                                                                                        batch_size : (530.0,)
 40%|████      | 2/5 [8:29:30<15:07:48, 18156.01s/trial, best loss: 0.13349479727305347]                                                                                        Trainingdataset:
 40%|████      | 2/5 [8:29:30<15:07:48, 18156.01s/trial, best loss: 0.13349479727305347]                                                                                        Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

 40%|████      | 2/5 [8:29:30<15:07:48, 18156.01s/trial, best loss: 0.13349479727305347]                                                                                        Using Evaluationdataset:
 40%|████      | 2/5 [8:29:30<15:07:48, 18156.01s/trial, best loss: 0.13349479727305347]                                                                                        Dataset Crops
    Number of datapoints: 55740
    Root Location: data/Crops
    Reduce: average

 40%|████      | 2/5 [8:29:30<15:07:48, 18156.01s/trial, best loss: 0.13349479727305347]                                                                                        runs/expID832000_TRAINode_ns:300000_ba:530_ode-units:255_gru-uts:100_lats:177_rec-lay:2_solver:dopri5_seed:6001_optim:adamax_stackin:1
 40%|████      | 2/5 [8:29:30<15:07:48, 18156.01s/trial, best loss: 0.13349479727305347]run_models.py --niters 50 -n 300000 -validn 60000 -l 177 --ode-rnn --ode-type gru --rnn-cell lstm --ode-method dopri5 --random-seed 6001 --optimizer adamax --num-search 5 --num-seeds 1 --hparams batch_size

run_models.py --niters 50 -n 300000 -validn 60000 -l 177 --ode-rnn --ode-type gru --rnn-cell lstm --ode-method dopri5 --random-seed 6001 --optimizer adamax --num-search 5 --num-seeds 1 --hparams batch_size

run_models.py --niters 50 -n 300000 -validn 60000 -l 177 --ode-rnn --ode-type gru --rnn-cell lstm --ode-method dopri5 --random-seed 6001 --optimizer adamax --num-search 5 --num-seeds 1 --hparams batch_size

                                                                                        0.8667563688554001
 40%|████      | 2/5 [12:14:51<15:07:48, 18156.01s/trial, best loss: 0.13349479727305347]                                                                                          at step 
 40%|████      | 2/5 [12:14:51<15:07:48, 18156.01s/trial, best loss: 0.13349479727305347]                                                                                         7002890
 40%|████      | 2/5 [12:14:51<15:07:48, 18156.01s/trial, best loss: 0.13349479727305347]                                                                                         {'loss': 0.13324363114459992, 'loss_variance': nan, 'status': 'ok', 'num_seeds': 1, 'best_acc': 0.8667563688554001, 'best_peak_step': 7002890, 'best_steps': [7002890]}
 40%|████      | 2/5 [12:14:51<15:07:48, 18156.01s/trial, best loss: 0.13349479727305347] 60%|██████    | 3/5 [12:14:51<9:18:51, 16765.70s/trial, best loss: 0.13324363114459992] build_posterior_wrapper took 0.001896 seconds

build_posterior_wrapper took 0.001896 seconds

build_posterior_wrapper took 0.001896 seconds

TPE using 3/3 trials with best loss 0.133244

TPE using 3/3 trials with best loss 0.133244

TPE using 3/3 trials with best loss 0.133244

                                                                                        Testing hyperparameters:
 60%|██████    | 3/5 [12:14:51<9:18:51, 16765.70s/trial, best loss: 0.13324363114459992]                                                                                        batch_size : (1500.0,)
 60%|██████    | 3/5 [12:14:51<9:18:51, 16765.70s/trial, best loss: 0.13324363114459992]                                                                                        Trainingdataset:
 60%|██████    | 3/5 [12:14:52<9:18:51, 16765.70s/trial, best loss: 0.13324363114459992]                                                                                        Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

 60%|██████    | 3/5 [12:14:52<9:18:51, 16765.70s/trial, best loss: 0.13324363114459992]                                                                                        Using Evaluationdataset:
 60%|██████    | 3/5 [12:14:52<9:18:51, 16765.70s/trial, best loss: 0.13324363114459992]                                                                                        Dataset Crops
    Number of datapoints: 55740
    Root Location: data/Crops
    Reduce: average

 60%|██████    | 3/5 [12:14:52<9:18:51, 16765.70s/trial, best loss: 0.13324363114459992]                                                                                        runs/expID5754000_TRAINode_ns:300000_ba:1500_ode-units:255_gru-uts:100_lats:177_rec-lay:2_solver:dopri5_seed:6001_optim:adamax_stackin:1
 60%|██████    | 3/5 [12:14:52<9:18:51, 16765.70s/trial, best loss: 0.13324363114459992]run_models.py --niters 50 -n 300000 -validn 60000 -l 177 --ode-rnn --ode-type gru --rnn-cell lstm --ode-method dopri5 --random-seed 6001 --optimizer adamax --num-search 5 --num-seeds 1 --hparams batch_size

run_models.py --niters 50 -n 300000 -validn 60000 -l 177 --ode-rnn --ode-type gru --rnn-cell lstm --ode-method dopri5 --random-seed 6001 --optimizer adamax --num-search 5 --num-seeds 1 --hparams batch_size

run_models.py --niters 50 -n 300000 -validn 60000 -l 177 --ode-rnn --ode-type gru --rnn-cell lstm --ode-method dopri5 --random-seed 6001 --optimizer adamax --num-search 5 --num-seeds 1 --hparams batch_size

run_models.py --niters 50 -n 300000 -validn 60000 -l 177 --ode-rnn --ode-type gru --rnn-cell lstm --ode-method dopri5 --random-seed 6001 --optimizer adamax --num-search 5 --num-seeds 1 --hparams batch_size

                                                                                        0.8670075349838536
 60%|██████    | 3/5 [13:50:00<9:18:51, 16765.70s/trial, best loss: 0.13324363114459992]                                                                                         at step 
 60%|██████    | 3/5 [13:50:00<9:18:51, 16765.70s/trial, best loss: 0.13324363114459992]                                                                                        7465500
 60%|██████    | 3/5 [13:50:00<9:18:51, 16765.70s/trial, best loss: 0.13324363114459992]                                                                                        {'loss': 0.13299246501614637, 'loss_variance': nan, 'status': 'ok', 'num_seeds': 1, 'best_acc': 0.8670075349838536, 'best_peak_step': 7465500, 'best_steps': [7465500]}
 60%|██████    | 3/5 [13:50:00<9:18:51, 16765.70s/trial, best loss: 0.13324363114459992] 80%|████████  | 4/5 [13:50:00<3:44:08, 13448.69s/trial, best loss: 0.13299246501614637]build_posterior_wrapper took 0.002183 seconds

build_posterior_wrapper took 0.002183 seconds

build_posterior_wrapper took 0.002183 seconds

build_posterior_wrapper took 0.002183 seconds

TPE using 4/4 trials with best loss 0.132992

TPE using 4/4 trials with best loss 0.132992

TPE using 4/4 trials with best loss 0.132992

TPE using 4/4 trials with best loss 0.132992

                                                                                        Testing hyperparameters:
 80%|████████  | 4/5 [13:50:00<3:44:08, 13448.69s/trial, best loss: 0.13299246501614637]                                                                                        batch_size : (290.0,)
 80%|████████  | 4/5 [13:50:00<3:44:08, 13448.69s/trial, best loss: 0.13299246501614637]                                                                                        Trainingdataset:
 80%|████████  | 4/5 [13:50:00<3:44:08, 13448.69s/trial, best loss: 0.13299246501614637]                                                                                        Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

 80%|████████  | 4/5 [13:50:00<3:44:08, 13448.69s/trial, best loss: 0.13299246501614637]                                                                                        Using Evaluationdataset:
 80%|████████  | 4/5 [13:50:00<3:44:08, 13448.69s/trial, best loss: 0.13299246501614637]                                                                                        Dataset Crops
    Number of datapoints: 55740
    Root Location: data/Crops
    Reduce: average

 80%|████████  | 4/5 [13:50:00<3:44:08, 13448.69s/trial, best loss: 0.13299246501614637]                                                                                        runs/expID3454000_TRAINode_ns:300000_ba:290_ode-units:255_gru-uts:100_lats:177_rec-lay:2_solver:dopri5_seed:6001_optim:adamax_stackin:1
 80%|████████  | 4/5 [13:50:00<3:44:08, 13448.69s/trial, best loss: 0.13299246501614637]run_models.py --niters 50 -n 300000 -validn 60000 -l 177 --ode-rnn --ode-type gru --rnn-cell lstm --ode-method dopri5 --random-seed 6001 --optimizer adamax --num-search 5 --num-seeds 1 --hparams batch_size

run_models.py --niters 50 -n 300000 -validn 60000 -l 177 --ode-rnn --ode-type gru --rnn-cell lstm --ode-method dopri5 --random-seed 6001 --optimizer adamax --num-search 5 --num-seeds 1 --hparams batch_size

run_models.py --niters 50 -n 300000 -validn 60000 -l 177 --ode-rnn --ode-type gru --rnn-cell lstm --ode-method dopri5 --random-seed 6001 --optimizer adamax --num-search 5 --num-seeds 1 --hparams batch_size

run_models.py --niters 50 -n 300000 -validn 60000 -l 177 --ode-rnn --ode-type gru --rnn-cell lstm --ode-method dopri5 --random-seed 6001 --optimizer adamax --num-search 5 --num-seeds 1 --hparams batch_size

run_models.py --niters 50 -n 300000 -validn 60000 -l 177 --ode-rnn --ode-type gru --rnn-cell lstm --ode-method dopri5 --random-seed 6001 --optimizer adamax --num-search 5 --num-seeds 1 --hparams batch_size

                                                                                        0.867491926803014
 80%|████████  | 4/5 [20:32:15<3:44:08, 13448.69s/trial, best loss: 0.13299246501614637]                                                                                         at step 
 80%|████████  | 4/5 [20:32:15<3:44:08, 13448.69s/trial, best loss: 0.13299246501614637]                                                                                        10718400
 80%|████████  | 4/5 [20:32:15<3:44:08, 13448.69s/trial, best loss: 0.13299246501614637]                                                                                        {'loss': 0.132508073196986, 'loss_variance': nan, 'status': 'ok', 'num_seeds': 1, 'best_acc': 0.867491926803014, 'best_peak_step': 10718400, 'best_steps': [10718400]}
 80%|████████  | 4/5 [20:32:15<3:44:08, 13448.69s/trial, best loss: 0.13299246501614637]100%|██████████| 5/5 [20:32:15<00:00, 16654.41s/trial, best loss: 0.132508073196986]    100%|██████████| 5/5 [20:32:15<00:00, 14787.03s/trial, best loss: 0.132508073196986]
ODE-RNN  True
Classic-RNN:  False
Stacked layers:  1
ODE-type:  gru
RNN-cell:  lstm
defaut adapted LR's!!
Used Optimizer: adamax
Used Ode-Solver dopri5

---------------------------------------------------------------------------------------------------------------------------------------------
TRIAL PROTOCOL:
---------------------------------------------------------------------------------------------------------------------------------------------
Trial: 0001  |  #runs: 1  |  Mean Acc.: 86.651 %  |  Std: nan %  |  Best Acc.: 86.651 % (Peak: 8900100 samples)  |  Hparams: {'batch_size': [330.0]}  |
Trial: 0002  |  #runs: 1  |  Mean Acc.: 86.561 %  |  Std: nan %  |  Best Acc.: 86.561 % (Peak: 8923350 samples)  |  Hparams: {'batch_size': [1010.0]}  |
Trial: 0003  |  #runs: 1  |  Mean Acc.: 86.676 %  |  Std: nan %  |  Best Acc.: 86.676 % (Peak: 7002890 samples)  |  Hparams: {'batch_size': [530.0]}  |
Trial: 0004  |  #runs: 1  |  Mean Acc.: 86.701 %  |  Std: nan %  |  Best Acc.: 86.701 % (Peak: 7465500 samples)  |  Hparams: {'batch_size': [1500.0]}  |
Trial: 0005  |  #runs: 1  |  Mean Acc.: 86.749 %  |  Std: nan %  |  Best Acc.: 86.749 % (Peak: 10718400 samples)  |  Hparams: {'batch_size': [290.0]}  |
---------------------------------------------------------------------------------------------------------------------------------------------
Best configuration mean: 86.749 % (+-nan) (best run: 86.749 %) , with Hyperparmeters: {'batch_size': [290.0]}
---------------------------------------------------------------------------------------------------------------------------------------------
