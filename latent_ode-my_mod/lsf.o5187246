Lmod has detected the following error: The following module(s) are unknown:
"pytorch/1.4.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "pytorch/1.4.0"



/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod/lib/plotting.py:178: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.
  plt.show(block=False)
/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod/run_models.py
run_models.py --niters 3 -n 300000 -b 8000 -l 15 --dataset crop --ode-rnn --rec-dims 100 --rec-layers 4 --gen-layers 1 --units 500 --gru-units 50 --classif --ode-method euler
  0%|          | 0/108 [00:00<?, ?it/s]  1%|          | 1/108 [05:46<10:17:48, 346.43s/it]Experiment 79377
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 4.429399 | Likelihood -1402.181152 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 2.164301633834839
Train CE loss (one batch): 2.164301633834839
Classification accuracy (TRAIN): 0.3486
Test MSE: 0.2812
Classification accuracy (TEST): 0.3522
Poisson likelihood: 0.0
CE loss: 4.429398536682129
-----------------------------------------------------------------------------------
  2%|▏         | 2/108 [12:33<10:44:11, 364.64s/it]  3%|▎         | 3/108 [18:23<10:30:18, 360.17s/it]Experiment 79377
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 2.102434 | Likelihood -812.363159 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 2.776362419128418
Train CE loss (one batch): 2.776362419128418
Classification accuracy (TRAIN): 0.2848
Test MSE: 0.1632
Classification accuracy (TEST): 0.3516
Poisson likelihood: 0.0
CE loss: 2.1024341583251953
-----------------------------------------------------------------------------------
  4%|▎         | 4/108 [25:09<10:48:05, 373.90s/it]  5%|▍         | 5/108 [30:55<10:27:22, 365.46s/it]Experiment 79377
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 2.057189 | Likelihood -711.726990 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 2.0446417331695557
Train CE loss (one batch): 2.0446417331695557
Classification accuracy (TRAIN): 0.2585
Test MSE: 0.1431
Classification accuracy (TEST): 0.3362
Poisson likelihood: 0.0
CE loss: 2.057189464569092
-----------------------------------------------------------------------------------
  6%|▌         | 6/108 [37:43<10:43:03, 378.27s/it]  6%|▋         | 7/108 [43:33<10:22:51, 370.01s/it]Experiment 79377
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.980946 | Likelihood -704.809570 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.9827115535736084
Train CE loss (one batch): 1.9827115535736084
Classification accuracy (TRAIN): 0.3551
Test MSE: 0.1417
Classification accuracy (TEST): 0.3522
Poisson likelihood: 0.0
CE loss: 1.9809458255767822
-----------------------------------------------------------------------------------
  7%|▋         | 8/108 [50:19<10:34:32, 380.73s/it]  8%|▊         | 9/108 [56:11<10:13:45, 371.98s/it]Experiment 79377
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.939750 | Likelihood -756.166382 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.9641610383987427
Train CE loss (one batch): 1.9641610383987427
Classification accuracy (TRAIN): 0.3491
Test MSE: 0.1520
Classification accuracy (TEST): 0.3522
Poisson likelihood: 0.0
CE loss: 1.9397499561309814
-----------------------------------------------------------------------------------
  9%|▉         | 10/108 [1:02:57<10:24:19, 382.24s/it] 10%|█         | 11/108 [1:08:45<10:01:23, 371.99s/it]Experiment 79377
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.923193 | Likelihood -756.637634 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.9354710578918457
Train CE loss (one batch): 1.9354710578918457
Classification accuracy (TRAIN): 0.3461
Test MSE: 0.1521
Classification accuracy (TEST): 0.3522
Poisson likelihood: 0.0
CE loss: 1.9231926202774048
-----------------------------------------------------------------------------------
 11%|█         | 12/108 [1:15:32<10:12:08, 382.59s/it] 12%|█▏        | 13/108 [1:21:23<9:50:29, 372.95s/it] Experiment 79377
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.946919 | Likelihood -795.174622 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.9635823965072632
Train CE loss (one batch): 1.9635823965072632
Classification accuracy (TRAIN): 0.3177
Test MSE: 0.1598
Classification accuracy (TEST): 0.3522
Poisson likelihood: 0.0
CE loss: 1.9469194412231445
-----------------------------------------------------------------------------------
 13%|█▎        | 14/108 [1:28:11<10:00:43, 383.44s/it] 14%|█▍        | 15/108 [1:34:03<9:39:47, 374.06s/it] Experiment 79377
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.921680 | Likelihood -778.726013 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.931416630744934
Train CE loss (one batch): 1.931416630744934
Classification accuracy (TRAIN): 0.3453
Test MSE: 0.1565
Classification accuracy (TEST): 0.4516
Poisson likelihood: 0.0
CE loss: 1.921679973602295
-----------------------------------------------------------------------------------
 15%|█▍        | 16/108 [1:40:50<9:48:59, 384.12s/it] 16%|█▌        | 17/108 [1:46:43<9:28:14, 374.67s/it]Experiment 79377
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.923660 | Likelihood -813.730103 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.9335938692092896
Train CE loss (one batch): 1.9335938692092896
Classification accuracy (TRAIN): 0.4281
Test MSE: 0.1635
Classification accuracy (TEST): 0.4630
Poisson likelihood: 0.0
CE loss: 1.9236600399017334
-----------------------------------------------------------------------------------
 17%|█▋        | 18/108 [1:53:31<9:36:49, 384.55s/it] 18%|█▊        | 19/108 [1:59:22<9:15:50, 374.73s/it]Experiment 79377
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.846896 | Likelihood -765.321167 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.8875523805618286
Train CE loss (one batch): 1.8875523805618286
Classification accuracy (TRAIN): 0.3543
Test MSE: 0.1538
Classification accuracy (TEST): 0.4436
Poisson likelihood: 0.0
CE loss: 1.8468955755233765
-----------------------------------------------------------------------------------
 19%|█▊        | 20/108 [2:06:10<9:24:08, 384.64s/it] 19%|█▉        | 21/108 [2:12:02<9:03:21, 374.73s/it]Experiment 79377
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.762517 | Likelihood -774.080322 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.837217092514038
Train CE loss (one batch): 1.837217092514038
Classification accuracy (TRAIN): 0.3571
Test MSE: 0.1556
Classification accuracy (TEST): 0.4136
Poisson likelihood: 0.0
CE loss: 1.7625168561935425
-----------------------------------------------------------------------------------
 20%|██        | 22/108 [2:18:51<9:11:45, 384.95s/it] 21%|██▏       | 23/108 [2:24:40<8:50:24, 374.40s/it]Experiment 79377
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.725300 | Likelihood -781.379456 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.8215287923812866
Train CE loss (one batch): 1.8215287923812866
Classification accuracy (TRAIN): 0.3909
Test MSE: 0.1570
Classification accuracy (TEST): 0.4496
Poisson likelihood: 0.0
CE loss: 1.7252997159957886
-----------------------------------------------------------------------------------
 22%|██▏       | 24/108 [2:31:30<8:58:59, 384.99s/it] 23%|██▎       | 25/108 [2:37:21<8:38:35, 374.88s/it]Experiment 79377
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.679977 | Likelihood -753.572083 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.7332662343978882
Train CE loss (one batch): 1.7332662343978882
Classification accuracy (TRAIN): 0.4201
Test MSE: 0.1515
Classification accuracy (TEST): 0.5170
Poisson likelihood: 0.0
CE loss: 1.6799771785736084
-----------------------------------------------------------------------------------
 24%|██▍       | 26/108 [2:44:09<8:45:37, 384.60s/it] 25%|██▌       | 27/108 [2:50:01<8:26:05, 374.88s/it]Experiment 79377
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.620401 | Likelihood -745.830566 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.7353519201278687
Train CE loss (one batch): 1.7353519201278687
Classification accuracy (TRAIN): 0.4206
Test MSE: 0.1499
Classification accuracy (TEST): 0.4696
Poisson likelihood: 0.0
CE loss: 1.62040114402771
-----------------------------------------------------------------------------------
 26%|██▌       | 28/108 [2:56:47<8:32:28, 384.36s/it] 27%|██▋       | 29/108 [3:02:40<8:13:25, 374.76s/it]Experiment 79377
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.584941 | Likelihood -748.311218 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.671263337135315
Train CE loss (one batch): 1.671263337135315
Classification accuracy (TRAIN): 0.4404
Test MSE: 0.1504
Classification accuracy (TEST): 0.4743
Poisson likelihood: 0.0
CE loss: 1.584940791130066
-----------------------------------------------------------------------------------
 28%|██▊       | 30/108 [3:09:27<8:20:01, 384.63s/it] 29%|██▊       | 31/108 [3:15:20<8:01:14, 374.99s/it]Experiment 79377
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.550641 | Likelihood -737.237000 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.673192024230957
Train CE loss (one batch): 1.673192024230957
Classification accuracy (TRAIN): 0.4455
Test MSE: 0.1482
Classification accuracy (TEST): 0.4983
Poisson likelihood: 0.0
CE loss: 1.550641417503357
-----------------------------------------------------------------------------------
 30%|██▉       | 32/108 [3:22:07<8:07:18, 384.71s/it] 31%|███       | 33/108 [3:27:59<7:48:36, 374.89s/it]Experiment 79377
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.479200 | Likelihood -762.691650 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.644392490386963
Train CE loss (one batch): 1.644392490386963
Classification accuracy (TRAIN): 0.4446
Test MSE: 0.1533
Classification accuracy (TEST): 0.5350
Poisson likelihood: 0.0
CE loss: 1.479199767112732
-----------------------------------------------------------------------------------
 31%|███▏      | 34/108 [3:34:48<7:54:51, 385.02s/it] 32%|███▏      | 35/108 [3:40:40<7:36:17, 375.03s/it]Experiment 79377
Epoch 0001 [Test seq (cond on sampled tp)] | Loss 1.431381 | Likelihood -777.332214 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.6072602272033691
Train CE loss (one batch): 1.6072602272033691
Classification accuracy (TRAIN): 0.4836
Test MSE: 0.1562
Classification accuracy (TEST): 0.5150
Poisson likelihood: 0.0
CE loss: 1.431381106376648
-----------------------------------------------------------------------------------
 33%|███▎      | 36/108 [3:47:22<7:40:03, 383.38s/it] 34%|███▍      | 37/108 [3:53:15<7:22:44, 374.14s/it]Experiment 79377
Epoch 0001 [Test seq (cond on sampled tp)] | Loss 1.414110 | Likelihood -748.131470 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.5346357822418213
Train CE loss (one batch): 1.5346357822418213
Classification accuracy (TRAIN): 0.5152
Test MSE: 0.1504
Classification accuracy (TEST): 0.5417
Poisson likelihood: 0.0
CE loss: 1.4141104221343994
-----------------------------------------------------------------------------------
 35%|███▌      | 38/108 [4:00:01<7:27:47, 383.82s/it] 36%|███▌      | 39/108 [4:05:54<7:10:33, 374.41s/it]Experiment 79377
Epoch 0001 [Test seq (cond on sampled tp)] | Loss 1.359403 | Likelihood -769.316406 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.5274343490600586
Train CE loss (one batch): 1.5274343490600586
Classification accuracy (TRAIN): 0.4880
Test MSE: 0.1546
Classification accuracy (TEST): 0.5944
Poisson likelihood: 0.0
CE loss: 1.3594032526016235
-----------------------------------------------------------------------------------
 37%|███▋      | 40/108 [4:12:36<7:13:44, 382.71s/it] 38%|███▊      | 41/108 [4:18:24<6:55:36, 372.19s/it]Experiment 79377
Epoch 0001 [Test seq (cond on sampled tp)] | Loss 1.310615 | Likelihood -772.751709 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.5117669105529785
Train CE loss (one batch): 1.5117669105529785
Classification accuracy (TRAIN): 0.5464
Test MSE: 0.1553
Classification accuracy (TEST): 0.6424
Poisson likelihood: 0.0
CE loss: 1.3106151819229126
-----------------------------------------------------------------------------------
 39%|███▉      | 42/108 [4:25:06<6:59:21, 381.24s/it] 40%|███▉      | 43/108 [4:30:53<6:41:57, 371.04s/it]Experiment 79377
Epoch 0001 [Test seq (cond on sampled tp)] | Loss 1.280312 | Likelihood -778.944824 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.4154495000839233
Train CE loss (one batch): 1.4154495000839233
Classification accuracy (TRAIN): 0.5616
Test MSE: 0.1565
Classification accuracy (TEST): 0.6558
Poisson likelihood: 0.0
CE loss: 1.2803117036819458
-----------------------------------------------------------------------------------
 41%|████      | 44/108 [4:37:35<6:45:40, 380.31s/it] 42%|████▏     | 45/108 [4:43:22<6:28:49, 370.31s/it]Experiment 79377
Epoch 0001 [Test seq (cond on sampled tp)] | Loss 1.213317 | Likelihood -792.545410 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.3905298709869385
Train CE loss (one batch): 1.3905298709869385
Classification accuracy (TRAIN): 0.5863
Test MSE: 0.1592
Classification accuracy (TEST): 0.6644
Poisson likelihood: 0.0
CE loss: 1.2133171558380127
-----------------------------------------------------------------------------------
 43%|████▎     | 46/108 [4:50:04<6:32:25, 379.77s/it] 44%|████▎     | 47/108 [4:55:50<6:15:51, 369.70s/it]Experiment 79377
Epoch 0001 [Test seq (cond on sampled tp)] | Loss 1.215022 | Likelihood -837.894775 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.400376796722412
Train CE loss (one batch): 1.400376796722412
Classification accuracy (TRAIN): 0.6060
Test MSE: 0.1683
Classification accuracy (TEST): 0.6478
Poisson likelihood: 0.0
CE loss: 1.215022087097168
-----------------------------------------------------------------------------------
 44%|████▍     | 48/108 [5:02:32<6:19:15, 379.27s/it] 45%|████▌     | 49/108 [5:08:18<6:03:09, 369.31s/it]Experiment 79377
Epoch 0001 [Test seq (cond on sampled tp)] | Loss 1.148115 | Likelihood -793.032349 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.3129361867904663
Train CE loss (one batch): 1.3129361867904663
Classification accuracy (TRAIN): 0.6396
Test MSE: 0.1593
Classification accuracy (TEST): 0.6831
Poisson likelihood: 0.0
CE loss: 1.1481153964996338
-----------------------------------------------------------------------------------
 46%|████▋     | 50/108 [5:15:01<6:06:41, 379.33s/it] 47%|████▋     | 51/108 [5:20:46<5:50:46, 369.24s/it]Experiment 79377
Epoch 0001 [Test seq (cond on sampled tp)] | Loss 1.107896 | Likelihood -796.060242 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.339106559753418
Train CE loss (one batch): 1.339106559753418
Classification accuracy (TRAIN): 0.6178
Test MSE: 0.1599
Classification accuracy (TEST): 0.6891
Poisson likelihood: 0.0
CE loss: 1.1078959703445435
-----------------------------------------------------------------------------------
 48%|████▊     | 52/108 [5:27:32<5:54:45, 380.11s/it] 49%|████▉     | 53/108 [5:33:20<5:39:38, 370.52s/it]Experiment 79377
Epoch 0001 [Test seq (cond on sampled tp)] | Loss 1.084021 | Likelihood -824.495911 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.289520025253296
Train CE loss (one batch): 1.289520025253296
Classification accuracy (TRAIN): 0.6252
Test MSE: 0.1656
Classification accuracy (TEST): 0.6898
Poisson likelihood: 0.0
CE loss: 1.0840212106704712
-----------------------------------------------------------------------------------
 50%|█████     | 54/108 [5:40:03<5:42:13, 380.26s/it] 51%|█████     | 55/108 [5:45:50<5:27:13, 370.45s/it]Experiment 79377
Epoch 0001 [Test seq (cond on sampled tp)] | Loss 1.045993 | Likelihood -806.896729 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.2707726955413818
Train CE loss (one batch): 1.2707726955413818
Classification accuracy (TRAIN): 0.6410
Test MSE: 0.1621
Classification accuracy (TEST): 0.7078
Poisson likelihood: 0.0
CE loss: 1.0459929704666138
-----------------------------------------------------------------------------------
 52%|█████▏    | 56/108 [5:52:32<5:29:09, 379.80s/it] 53%|█████▎    | 57/108 [5:58:23<5:15:27, 371.13s/it]Experiment 79377
Epoch 0001 [Test seq (cond on sampled tp)] | Loss 1.084731 | Likelihood -794.113098 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.2863974571228027
Train CE loss (one batch): 1.2863974571228027
Classification accuracy (TRAIN): 0.6348
Test MSE: 0.1596
Classification accuracy (TEST): 0.6885
Poisson likelihood: 0.0
CE loss: 1.084730625152588
-----------------------------------------------------------------------------------
 54%|█████▎    | 58/108 [6:05:08<5:17:45, 381.31s/it] 55%|█████▍    | 59/108 [6:10:57<5:03:26, 371.56s/it]Experiment 79377
Epoch 0001 [Test seq (cond on sampled tp)] | Loss 1.110392 | Likelihood -804.325562 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.2452261447906494
Train CE loss (one batch): 1.2452261447906494
Classification accuracy (TRAIN): 0.6382
Test MSE: 0.1616
Classification accuracy (TEST): 0.6785
Poisson likelihood: 0.0
CE loss: 1.1103922128677368
-----------------------------------------------------------------------------------
 56%|█████▌    | 60/108 [6:17:52<5:07:39, 384.58s/it] 56%|█████▋    | 61/108 [6:23:58<4:56:51, 378.97s/it]Experiment 79377
Epoch 0001 [Test seq (cond on sampled tp)] | Loss 1.064788 | Likelihood -795.545044 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.2268943786621094
Train CE loss (one batch): 1.2268943786621094
Classification accuracy (TRAIN): 0.6484
Test MSE: 0.1598
Classification accuracy (TEST): 0.6958
Poisson likelihood: 0.0
CE loss: 1.0647882223129272
-----------------------------------------------------------------------------------
 57%|█████▋    | 62/108 [6:31:13<5:03:28, 395.85s/it] 58%|█████▊    | 63/108 [6:37:19<4:50:06, 386.81s/it]Experiment 79377
Epoch 0001 [Test seq (cond on sampled tp)] | Loss 1.033147 | Likelihood -795.034973 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.187188982963562
Train CE loss (one batch): 1.187188982963562
Classification accuracy (TRAIN): 0.6644
Test MSE: 0.1597
Classification accuracy (TEST): 0.7145
Poisson likelihood: 0.0
CE loss: 1.0331467390060425
-----------------------------------------------------------------------------------
 59%|█████▉    | 64/108 [6:44:32<4:53:54, 400.78s/it] 60%|██████    | 65/108 [6:50:38<4:39:41, 390.28s/it]Experiment 79377
Epoch 0001 [Test seq (cond on sampled tp)] | Loss 1.005134 | Likelihood -780.598145 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.1811281442642212
Train CE loss (one batch): 1.1811281442642212
Classification accuracy (TRAIN): 0.6605
Test MSE: 0.1569
Classification accuracy (TEST): 0.7058
Poisson likelihood: 0.0
CE loss: 1.0051339864730835
-----------------------------------------------------------------------------------
 61%|██████    | 66/108 [6:57:42<4:40:17, 400.41s/it] 62%|██████▏   | 67/108 [7:03:53<4:27:37, 391.64s/it]Experiment 79377
Epoch 0001 [Test seq (cond on sampled tp)] | Loss 1.011613 | Likelihood -797.004944 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.1871379613876343
Train CE loss (one batch): 1.1871379613876343
Classification accuracy (TRAIN): 0.6679
Test MSE: 0.1601
Classification accuracy (TEST): 0.7218
Poisson likelihood: 0.0
CE loss: 1.0116134881973267
-----------------------------------------------------------------------------------
 63%|██████▎   | 68/108 [7:10:53<4:26:45, 400.13s/it] 64%|██████▍   | 69/108 [7:17:02<4:14:06, 390.94s/it]Experiment 79377
Epoch 0001 [Test seq (cond on sampled tp)] | Loss 0.985727 | Likelihood -797.913025 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.1520262956619263
Train CE loss (one batch): 1.1520262956619263
Classification accuracy (TRAIN): 0.6697
Test MSE: 0.1603
Classification accuracy (TEST): 0.7145
Poisson likelihood: 0.0
CE loss: 0.9857265949249268
-----------------------------------------------------------------------------------
 65%|██████▍   | 70/108 [7:24:28<4:18:03, 407.45s/it] 66%|██████▌   | 71/108 [7:30:29<4:02:38, 393.47s/it]Experiment 79377
Epoch 0002 [Test seq (cond on sampled tp)] | Loss 0.974825 | Likelihood -774.857239 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.1394264698028564
Train CE loss (one batch): 1.1394264698028564
Classification accuracy (TRAIN): 0.6710
Test MSE: 0.1557
Classification accuracy (TEST): 0.7218
Poisson likelihood: 0.0
CE loss: 0.9748245477676392
-----------------------------------------------------------------------------------
 67%|██████▋   | 72/108 [7:37:46<4:03:57, 406.60s/it] 68%|██████▊   | 73/108 [7:44:04<3:52:06, 397.90s/it]Experiment 79377
Epoch 0002 [Test seq (cond on sampled tp)] | Loss 0.964021 | Likelihood -790.302246 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.0775847434997559
Train CE loss (one batch): 1.0775847434997559
Classification accuracy (TRAIN): 0.6953
Test MSE: 0.1588
Classification accuracy (TEST): 0.7292
Poisson likelihood: 0.0
CE loss: 0.9640211462974548
-----------------------------------------------------------------------------------
 69%|██████▊   | 74/108 [7:51:09<3:50:04, 406.01s/it] 69%|██████▉   | 75/108 [7:57:27<3:38:40, 397.58s/it]Experiment 79377
Epoch 0002 [Test seq (cond on sampled tp)] | Loss 0.949208 | Likelihood -761.102234 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.0862042903900146
Train CE loss (one batch): 1.0862042903900146
Classification accuracy (TRAIN): 0.6877
Test MSE: 0.1530
Classification accuracy (TEST): 0.7332
Poisson likelihood: 0.0
CE loss: 0.9492083787918091
-----------------------------------------------------------------------------------
 70%|███████   | 76/108 [8:04:37<3:37:18, 407.47s/it] 71%|███████▏  | 77/108 [8:10:41<3:23:39, 394.19s/it]Experiment 79377
Epoch 0002 [Test seq (cond on sampled tp)] | Loss 0.971052 | Likelihood -779.838745 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.0810117721557617
Train CE loss (one batch): 1.0810117721557617
Classification accuracy (TRAIN): 0.6943
Test MSE: 0.1567
Classification accuracy (TEST): 0.7278
Poisson likelihood: 0.0
CE loss: 0.9710521697998047
-----------------------------------------------------------------------------------
 72%|███████▏  | 78/108 [8:17:44<3:21:25, 402.85s/it] 73%|███████▎  | 79/108 [8:23:41<3:08:08, 389.27s/it]Experiment 79377
Epoch 0002 [Test seq (cond on sampled tp)] | Loss 0.939062 | Likelihood -765.927124 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.04424250125885
Train CE loss (one batch): 1.04424250125885
Classification accuracy (TRAIN): 0.7045
Test MSE: 0.1539
Classification accuracy (TEST): 0.7298
Poisson likelihood: 0.0
CE loss: 0.9390621185302734
-----------------------------------------------------------------------------------
 74%|███████▍  | 80/108 [8:30:41<3:05:52, 398.29s/it] 75%|███████▌  | 81/108 [8:36:44<2:54:30, 387.81s/it]Experiment 79377
Epoch 0002 [Test seq (cond on sampled tp)] | Loss 0.921253 | Likelihood -790.664368 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.055878758430481
Train CE loss (one batch): 1.055878758430481
Classification accuracy (TRAIN): 0.6964
Test MSE: 0.1589
Classification accuracy (TEST): 0.7425
Poisson likelihood: 0.0
CE loss: 0.9212527871131897
-----------------------------------------------------------------------------------
 76%|███████▌  | 82/108 [8:43:44<2:52:12, 397.40s/it] 77%|███████▋  | 83/108 [8:49:46<2:41:07, 386.72s/it]Experiment 79377
Epoch 0002 [Test seq (cond on sampled tp)] | Loss 0.928501 | Likelihood -797.693176 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.069284439086914
Train CE loss (one batch): 1.069284439086914
Classification accuracy (TRAIN): 0.6955
Test MSE: 0.1603
Classification accuracy (TEST): 0.7445
Poisson likelihood: 0.0
CE loss: 0.9285007119178772
-----------------------------------------------------------------------------------
 78%|███████▊  | 84/108 [8:56:37<2:37:40, 394.18s/it] 79%|███████▊  | 85/108 [9:02:36<2:27:04, 383.68s/it]Experiment 79377
Epoch 0002 [Test seq (cond on sampled tp)] | Loss 0.894659 | Likelihood -798.879761 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.0229488611221313
Train CE loss (one batch): 1.0229488611221313
Classification accuracy (TRAIN): 0.7105
Test MSE: 0.1605
Classification accuracy (TEST): 0.7565
Poisson likelihood: 0.0
CE loss: 0.8946590423583984
-----------------------------------------------------------------------------------
 80%|███████▉  | 86/108 [9:09:39<2:24:58, 395.41s/it] 81%|████████  | 87/108 [9:15:37<2:14:30, 384.29s/it]Experiment 79377
Epoch 0002 [Test seq (cond on sampled tp)] | Loss 0.897609 | Likelihood -805.549866 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.1136400699615479
Train CE loss (one batch): 1.1136400699615479
Classification accuracy (TRAIN): 0.6849
Test MSE: 0.1618
Classification accuracy (TEST): 0.7465
Poisson likelihood: 0.0
CE loss: 0.8976091742515564
-----------------------------------------------------------------------------------
 81%|████████▏ | 88/108 [9:22:33<2:11:14, 393.73s/it] 82%|████████▏ | 89/108 [9:28:32<2:01:19, 383.11s/it]Experiment 79377
Epoch 0002 [Test seq (cond on sampled tp)] | Loss 0.964231 | Likelihood -801.157288 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.0364124774932861
Train CE loss (one batch): 1.0364124774932861
Classification accuracy (TRAIN): 0.7094
Test MSE: 0.1610
Classification accuracy (TEST): 0.7265
Poisson likelihood: 0.0
CE loss: 0.9642312526702881
-----------------------------------------------------------------------------------
 83%|████████▎ | 90/108 [9:35:28<1:57:56, 393.14s/it] 84%|████████▍ | 91/108 [9:41:28<1:48:31, 383.03s/it]Experiment 79377
Epoch 0002 [Test seq (cond on sampled tp)] | Loss 0.939075 | Likelihood -818.374329 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.104049801826477
Train CE loss (one batch): 1.104049801826477
Classification accuracy (TRAIN): 0.6785
Test MSE: 0.1644
Classification accuracy (TEST): 0.7118
Poisson likelihood: 0.0
CE loss: 0.9390748143196106
-----------------------------------------------------------------------------------
 85%|████████▌ | 92/108 [9:48:31<1:45:23, 395.22s/it] 86%|████████▌ | 93/108 [9:54:25<1:35:43, 382.90s/it]Experiment 79377
Epoch 0002 [Test seq (cond on sampled tp)] | Loss 0.928281 | Likelihood -839.912781 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.1125718355178833
Train CE loss (one batch): 1.1125718355178833
Classification accuracy (TRAIN): 0.6709
Test MSE: 0.1687
Classification accuracy (TEST): 0.7505
Poisson likelihood: 0.0
CE loss: 0.9282808303833008
-----------------------------------------------------------------------------------
 87%|████████▋ | 94/108 [10:01:32<1:32:23, 395.95s/it] 88%|████████▊ | 95/108 [10:07:30<1:23:21, 384.76s/it]Experiment 79377
Epoch 0002 [Test seq (cond on sampled tp)] | Loss 0.906250 | Likelihood -826.407043 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.1345500946044922
Train CE loss (one batch): 1.1345500946044922
Classification accuracy (TRAIN): 0.6739
Test MSE: 0.1660
Classification accuracy (TEST): 0.7458
Poisson likelihood: 0.0
CE loss: 0.9062501192092896
-----------------------------------------------------------------------------------
 89%|████████▉ | 96/108 [10:14:35<1:19:20, 396.73s/it] 90%|████████▉ | 97/108 [10:20:37<1:10:49, 386.32s/it]Experiment 79377
Epoch 0002 [Test seq (cond on sampled tp)] | Loss 0.931847 | Likelihood -850.742126 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.0696220397949219
Train CE loss (one batch): 1.0696220397949219
Classification accuracy (TRAIN): 0.6941
Test MSE: 0.1709
Classification accuracy (TEST): 0.7338
Poisson likelihood: 0.0
CE loss: 0.9318469166755676
-----------------------------------------------------------------------------------
 91%|█████████ | 98/108 [10:27:32<1:05:49, 394.95s/it] 92%|█████████▏| 99/108 [10:33:39<57:57, 386.44s/it]  Experiment 79377
Epoch 0002 [Test seq (cond on sampled tp)] | Loss 0.920058 | Likelihood -803.856934 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.0738344192504883
Train CE loss (one batch): 1.0738344192504883
Classification accuracy (TRAIN): 0.6816
Test MSE: 0.1615
Classification accuracy (TEST): 0.7645
Poisson likelihood: 0.0
CE loss: 0.9200583696365356
-----------------------------------------------------------------------------------
 93%|█████████▎| 100/108 [10:40:30<52:30, 393.79s/it] 94%|█████████▎| 101/108 [10:46:38<45:02, 386.00s/it]Experiment 79377
Epoch 0002 [Test seq (cond on sampled tp)] | Loss 0.900132 | Likelihood -793.277344 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.1273096799850464
Train CE loss (one batch): 1.1273096799850464
Classification accuracy (TRAIN): 0.6727
Test MSE: 0.1594
Classification accuracy (TEST): 0.7452
Poisson likelihood: 0.0
CE loss: 0.9001321792602539
-----------------------------------------------------------------------------------
 94%|█████████▍| 102/108 [10:53:37<39:35, 395.91s/it] 95%|█████████▌| 103/108 [10:59:34<32:02, 384.47s/it]Experiment 79377
Epoch 0002 [Test seq (cond on sampled tp)] | Loss 0.963986 | Likelihood -802.211182 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.1084938049316406
Train CE loss (one batch): 1.1084938049316406
Classification accuracy (TRAIN): 0.6697
Test MSE: 0.1612
Classification accuracy (TEST): 0.7191
Poisson likelihood: 0.0
CE loss: 0.9639864563941956
-----------------------------------------------------------------------------------
 96%|█████████▋| 104/108 [11:06:40<26:27, 396.94s/it] 97%|█████████▋| 105/108 [11:12:38<19:15, 385.10s/it]Experiment 79377
Epoch 0002 [Test seq (cond on sampled tp)] | Loss 0.890268 | Likelihood -775.949646 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.0602535009384155
Train CE loss (one batch): 1.0602535009384155
Classification accuracy (TRAIN): 0.6914
Test MSE: 0.1559
Classification accuracy (TEST): 0.7478
Poisson likelihood: 0.0
CE loss: 0.8902676701545715
-----------------------------------------------------------------------------------
 98%|█████████▊| 106/108 [11:19:39<13:11, 395.89s/it] 99%|█████████▉| 107/108 [11:25:43<06:26, 386.43s/it]Experiment 79377
Epoch 0003 [Test seq (cond on sampled tp)] | Loss 0.893805 | Likelihood -784.405945 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.0684391260147095
Train CE loss (one batch): 1.0684391260147095
Classification accuracy (TRAIN): 0.6974
Test MSE: 0.1576
Classification accuracy (TEST): 0.7525
Poisson likelihood: 0.0
CE loss: 0.8938052654266357
-----------------------------------------------------------------------------------
100%|██████████| 108/108 [11:32:28<00:00, 391.97s/it]100%|██████████| 108/108 [11:32:28<00:00, 384.71s/it]
Couldn't import umap
Sampling dataset of 300000 training examples
Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
