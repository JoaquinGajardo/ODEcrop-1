Lmod has detected the following error: The following module(s) are unknown:
"pytorch/1.4.0"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore-cache load "pytorch/1.4.0"



/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod/run_models.py
run_models.py --niters 5 -n 300000 -b 2000 -l 35 --dataset crop --ode-rnn --rec-dims 100 --rec-layers 4 --gen-layers 1 --units 500 --gru-units 50 --classif --ode-method euler
  0%|          | 0/720 [00:00<?, ?it/s]  0%|          | 1/720 [02:05<25:09:49, 125.99s/it]  0%|          | 2/720 [04:11<25:07:15, 125.95s/it]  0%|          | 3/720 [06:18<25:06:03, 126.03s/it]  1%|          | 4/720 [08:23<25:00:08, 125.71s/it]  1%|          | 5/720 [10:25<24:47:39, 124.84s/it]  1%|          | 6/720 [12:26<24:32:17, 123.72s/it]Experiment 4995
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 2.041007 | Likelihood -1026.828613 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 2.0389668941497803
Train CE loss (one batch): 2.0389668941497803
Classification accuracy (TRAIN): 0.3320
Test MSE: 0.2061
Classification accuracy (TEST): 0.3522
Poisson likelihood: 0.0
CE loss: 2.0410068035125732
-----------------------------------------------------------------------------------
  1%|          | 7/720 [15:45<28:56:21, 146.12s/it]  1%|          | 8/720 [17:43<27:15:36, 137.83s/it]  1%|▏         | 9/720 [19:41<26:00:21, 131.68s/it]  1%|▏         | 10/720 [21:39<25:10:14, 127.63s/it]  2%|▏         | 11/720 [23:36<24:30:29, 124.44s/it]  2%|▏         | 12/720 [25:31<23:56:59, 121.78s/it]  2%|▏         | 13/720 [27:25<23:26:10, 119.34s/it]Experiment 4995
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.919435 | Likelihood -1084.123413 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.9582860469818115
Train CE loss (one batch): 1.9582860469818115
Classification accuracy (TRAIN): 0.3420
Test MSE: 0.2176
Classification accuracy (TEST): 0.3536
Poisson likelihood: 0.0
CE loss: 1.919434905052185
-----------------------------------------------------------------------------------
  2%|▏         | 14/720 [30:34<27:29:21, 140.17s/it]  2%|▏         | 15/720 [32:28<25:55:11, 132.36s/it]  2%|▏         | 16/720 [34:23<24:50:23, 127.02s/it]  2%|▏         | 17/720 [36:16<24:02:07, 123.08s/it]  2%|▎         | 18/720 [38:11<23:29:48, 120.50s/it]  3%|▎         | 19/720 [40:05<23:04:45, 118.52s/it]  3%|▎         | 20/720 [41:58<22:45:26, 117.04s/it]Experiment 4995
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.809808 | Likelihood -1326.656250 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.834220051765442
Train CE loss (one batch): 1.834220051765442
Classification accuracy (TRAIN): 0.3600
Test MSE: 0.2661
Classification accuracy (TEST): 0.3649
Poisson likelihood: 0.0
CE loss: 1.8098076581954956
-----------------------------------------------------------------------------------
  3%|▎         | 21/720 [44:58<26:21:22, 135.74s/it]  3%|▎         | 22/720 [46:46<24:43:50, 127.55s/it]  3%|▎         | 23/720 [48:35<23:35:32, 121.85s/it]  3%|▎         | 24/720 [50:23<22:46:13, 117.78s/it]  3%|▎         | 25/720 [52:12<22:13:24, 115.11s/it]  4%|▎         | 26/720 [54:00<21:45:49, 112.90s/it]  4%|▍         | 27/720 [55:49<21:30:18, 111.71s/it]Experiment 4995
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.586189 | Likelihood -1389.563477 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.7145777940750122
Train CE loss (one batch): 1.7145777940750122
Classification accuracy (TRAIN): 0.4300
Test MSE: 0.2786
Classification accuracy (TEST): 0.5177
Poisson likelihood: 0.0
CE loss: 1.5861890316009521
-----------------------------------------------------------------------------------
  4%|▍         | 28/720 [58:47<25:20:52, 131.87s/it]  4%|▍         | 29/720 [1:00:36<23:56:42, 124.75s/it]  4%|▍         | 30/720 [1:02:24<22:58:41, 119.89s/it]  4%|▍         | 31/720 [1:04:12<22:13:54, 116.16s/it]  4%|▍         | 32/720 [1:06:01<21:47:30, 114.03s/it]  5%|▍         | 33/720 [1:07:49<21:27:06, 112.41s/it]  5%|▍         | 34/720 [1:09:38<21:12:21, 111.29s/it]Experiment 4995
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.424594 | Likelihood -1353.312622 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.60933518409729
Train CE loss (one batch): 1.60933518409729
Classification accuracy (TRAIN): 0.4840
Test MSE: 0.2714
Classification accuracy (TEST): 0.5424
Poisson likelihood: 0.0
CE loss: 1.4245936870574951
-----------------------------------------------------------------------------------
  5%|▍         | 35/720 [1:12:37<25:02:01, 131.56s/it]  5%|▌         | 36/720 [1:14:25<23:41:13, 124.67s/it]  5%|▌         | 37/720 [1:16:13<22:41:35, 119.61s/it]  5%|▌         | 38/720 [1:18:02<22:02:38, 116.36s/it]  5%|▌         | 39/720 [1:19:50<21:31:41, 113.80s/it]  6%|▌         | 40/720 [1:21:39<21:12:41, 112.30s/it]  6%|▌         | 41/720 [1:23:27<20:56:13, 111.01s/it]Experiment 4995
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.339056 | Likelihood -1320.537231 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.4852501153945923
Train CE loss (one batch): 1.4852501153945923
Classification accuracy (TRAIN): 0.5490
Test MSE: 0.2648
Classification accuracy (TEST): 0.5504
Poisson likelihood: 0.0
CE loss: 1.3390562534332275
-----------------------------------------------------------------------------------
  6%|▌         | 42/720 [1:26:25<24:42:02, 131.15s/it]  6%|▌         | 43/720 [1:28:14<23:24:06, 124.44s/it]  6%|▌         | 44/720 [1:30:01<22:25:19, 119.41s/it]  6%|▋         | 45/720 [1:31:50<21:48:57, 116.35s/it]  6%|▋         | 46/720 [1:33:39<21:20:23, 113.98s/it]  7%|▋         | 47/720 [1:35:27<20:58:54, 112.24s/it]  7%|▋         | 48/720 [1:37:15<20:44:00, 111.07s/it]Experiment 4995
Epoch 0000 [Test seq (cond on sampled tp)] | Loss 1.160010 | Likelihood -1213.341064 | KL fp 0.0000 | FP STD 0.0000|
KL coef: 0.0
Train loss (one batch): 1.4140796661376953
Train CE loss (one batch): 1.4140796661376953
Classification accuracy (TRAIN): 0.5720
Test MSE: 0.2434
Classification accuracy (TEST): 0.6491
Poisson likelihood: 0.0
CE loss: 1.1600103378295898
-----------------------------------------------------------------------------------
  7%|▋         | 49/720 [1:40:14<24:29:33, 131.41s/it]  7%|▋         | 50/720 [1:42:03<23:12:03, 124.66s/it]  7%|▋         | 51/720 [1:43:52<22:17:32, 119.96s/it]  7%|▋         | 52/720 [1:45:40<21:36:13, 116.43s/it]  7%|▋         | 53/720 [1:47:30<21:10:08, 114.26s/it]  8%|▊         | 54/720 [1:49:17<20:46:22, 112.29s/it]  8%|▊         | 55/720 [1:51:06<20:34:04, 111.35s/it]Couldn't import umap
Sampling dataset of 300000 training examples
Dataset Crops
    Number of datapoints: 287858
    Root Location: data/Crops
    Reduce: average

Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Number of labeled examples: 1499
plotting....
Computing loss... 
Traceback (most recent call last):
  File "run_models.py", line 304, in <module>
    n_traj_samples = 3, kl_coef = kl_coef)
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod/lib/utils.py", line 549, in compute_loss_all_batches
    n_traj_samples = n_traj_samples, kl_coef = kl_coef)
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod/lib/base_models.py", line 135, in compute_all_losses
    mask = (batch_dict["mask_predicted_data"]) ) # this mask gives UserWarnings # torch.BoolTensor
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod/lib/base_models.py", line 115, in get_mse
    log_density_data = compute_mse(pred_y, truth, mask = mask)
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod/lib/likelihood_eval.py", line 276, in compute_mse
    res = compute_masked_likelihood(mu, data, mask, mse)
  File "/cluster/work/igp_psr/metzgern/ODEcrop/latent_ode-my_mod/lib/likelihood_eval.py", line 192, in compute_masked_likelihood
    data_masked = torch.masked_select(data[i,k,:,j], mask[i,k,:,j].bool()) #byte()
KeyboardInterrupt
  8%|▊         | 55/720 [1:53:43<22:55:08, 124.07s/it]
